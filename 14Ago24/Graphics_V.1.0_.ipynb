{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Índice\n",
    "\n",
    "1. [General Statistics](#1)\n",
    "2. [Boxplots](#2)\n",
    "3. [First Integer Helicity Betta vs Gamma](#3)\n",
    "4. [Sum Absolute Helicity Betta vs Gamma](#4)\n",
    "5. [First Integer Enstrophy Betta vs Gamma](#5)\n",
    "6. [3D Curl Comparisons](#6)\n",
    "7. [Individual 3D Curl Baseline vs Experimental Color](#7)\n",
    "8. [Velocity Field Baseline Nivel](#8)\n",
    "9. [Velocity Field MEI Nivel](#9)\n",
    "10. [Comparison Moduli before and after for MEI](#10)\n",
    "11. [Comparison Derivatives Histograms](#11)\n",
    "12. [Comparison Time Series Laser](#12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = r\"F:\\Datos\\12Ago24\"\n",
    "\n",
    "# Horarios ajustados de mediciones de línea base y de intervenciones experimentales\n",
    "\n",
    "lab_b_matutino_base_times = {\n",
    "    '01': \"10:39:59.065\",\n",
    "    '02': \"11:19:56.844\",\n",
    "    '03': \"12:00:00.896\",\n",
    "    '04': \"12:39:59.139\",\n",
    "    '05': \"13:19:59.461\"\n",
    "}\n",
    "\n",
    "# Horarios de intervenciones experimentales\n",
    "lab_b_matutino_intervention_times = {\n",
    "    '01': \"10:59:59.414\",\n",
    "    '02': \"11:39:59.104\",\n",
    "    '03': \"12:19:59.778\",\n",
    "    '04': \"13:00:01.295\"\n",
    "}\n",
    "\n",
    "# Horarios de mediciones de línea base para Lab_A en turno matutino\n",
    "lab_a_matutino_base_times = {\n",
    "    '01': \"10:39:59.065\",\n",
    "    '02': \"11:19:56.844\",\n",
    "    '03': \"12:00:00.896\",\n",
    "    '04': \"12:39:59.139\",\n",
    "    '05': \"13:19:59.461\"\n",
    "}\n",
    "\n",
    "# Horarios de intervenciones experimentales para Lab_A en turno matutino\n",
    "lab_a_matutino_intervention_times = {\n",
    "    '01': \"10:59:59.414\",\n",
    "    '02': \"11:39:59.104\",\n",
    "    '03': \"12:19:59.778\",\n",
    "    '04': \"13:00:01.295\"\n",
    "}\n",
    "\n",
    "n_change = {\"Lab_Betta\":\"Lab_Betta\", \"Lab_Gamma\":\"Lab_Gamma\"}\n",
    "\n",
    "triad_names = {\n",
    "    \"FRT\": \"Frontal-Derecho-Superior\",  \n",
    "    \"PLB\": \"Trasero-Izquierdo-Inferior\",  \n",
    "    \"FLT\": \"Frontal-Izquierdo-Superior\",  \n",
    "    \"PRB\": \"Trasero-Derecho-Inferior\",  \n",
    "    \"FRB\": \"Frontal-Derecho-Inferior\",  \n",
    "    \"PLT\": \"Trasero-Izquierdo-Superior\",  \n",
    "    \"FLB\": \"Frontal-Izquierdo-Inferior\",  \n",
    "    \"PRT\": \"Trasero-Derecho-Superior\",  \n",
    "    \"RTB\": \"Derecho-Superior-Inferior\",  \n",
    "    \"FLP\": \"Frontal-Izquierdo-Trasero\",  \n",
    "    \"LTB\": \"Izquierdo-Superior-Inferior\",  \n",
    "    \"FRP\": \"Frontal-Derecho-Trasero\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\n",
    "\n",
    "$$\n",
    "\\Huge \\text{General Statistcs}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking directory: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.V - Lab_Betta\n",
      "Directory does not exist: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.V - Lab_Betta\n",
      "Checking directory: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.M - Lab_Betta\n",
      "Checking directory: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.V - Lab_Gamma\n",
      "Directory does not exist: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.V - Lab_Gamma\n",
      "Checking directory: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.M - Lab_Gamma\n",
      "Archivo Excel generado exitosamente en: E:\\Pruebas\\14Sep24\\General_Statistics_14Sep24.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis, skew, iqr\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "\n",
    "# Función para leer datos del sensor desde un archivo\n",
    "def read_sensor_data(filepath):\n",
    "    data = []\n",
    "    timestamps = []\n",
    "    num_elements = None\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(' -> ')\n",
    "                if len(parts) > 1:\n",
    "                    timestamps.append(parts[0])\n",
    "                    numbers = parts[1].strip('()').split(',')\n",
    "                    try:\n",
    "                        number_list = [float(num.strip()) for num in numbers]\n",
    "                        if num_elements is None:\n",
    "                            num_elements = len(number_list)\n",
    "                        if len(number_list) == num_elements:\n",
    "                            data.append(number_list)\n",
    "                        else:\n",
    "                            print(f\"Inconsistent number of elements in file {filepath}, line: {line.strip()}\")\n",
    "                    except ValueError:\n",
    "                        print(f\"Value error in file {filepath}, line: {line.strip()}\")\n",
    "                        continue\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Unicode decode error in file {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filepath}: {e}\")\n",
    "    return timestamps, np.array(data).T\n",
    "\n",
    "# Función para analizar el contenido de una carpeta\n",
    "def analyze_folder(root_folder):\n",
    "    data_per_file = {}\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        # Evitar carpetas llamadas \"Data Analysis\"\n",
    "        if 'Data Analysis' in dirs:\n",
    "            dirs.remove('Data Analysis')\n",
    "\n",
    "        for filename in files:\n",
    "            if filename.startswith(\"0\") and filename.endswith((\"negra.txt\")):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                timestamps, data = read_sensor_data(file_path)\n",
    "                if data.size > 0:\n",
    "                    data_per_file[filename] = (timestamps, data, filename)\n",
    "    return data_per_file\n",
    "\n",
    "# Función para generar estadísticas de los datos\n",
    "def generate_statistics(data):\n",
    "    return {\n",
    "        'mean': np.mean(data, axis=1),\n",
    "        'median': np.median(data, axis=1),\n",
    "        'variance': np.var(data, axis=1),\n",
    "        'stdDev': np.std(data, axis=1),\n",
    "        'min': np.min(data, axis=1),\n",
    "        'max': np.max(data, axis=1),\n",
    "        'firstQuartile': np.percentile(data, 25, axis=1),\n",
    "        'thirdQuartile': np.percentile(data, 75, axis=1),\n",
    "        'iqr': iqr(data, axis=1),\n",
    "        'trimmedVariance': [np.var(np.trim_zeros(np.sort(sensor_data))) for sensor_data in data],\n",
    "        'kurtosis': kurtosis(data, axis=1, fisher=True, bias=False),\n",
    "        'skewness': skew(data, axis=1, bias=False)\n",
    "    }\n",
    "\n",
    "# Función para extraer la fecha del directorio root_folder\n",
    "def extract_date_from_root_folder(root_folder):\n",
    "    return os.path.basename(root_folder)\n",
    "\n",
    "# Función para formatear las estadísticas\n",
    "def format_statistics(stats, fmt=\".10f\"):\n",
    "    return {key: [f\"{val:{fmt}}\" for val in values] for key, values in stats.items()}\n",
    "\n",
    "# Función para asignar colores basados en el sufijo del archivo\n",
    "def get_color_for_file(filename):\n",
    "    if \"negra\" in filename:\n",
    "        return \"black\"\n",
    "\n",
    "\n",
    "# Función para generar los gráficos y los PDFs\n",
    "def plot_comparison_grid(data_per_file, output_pdf_folder, output_img_folder, output_text_folder, lab, session, date, workbook):\n",
    "    component_names = [\"FRONT(A0)\", \"REAR(A1)\", \"LEFT(A2)\", \"RIGHT(A3)\", \"TOP(A4)\", \"BOTTOM(A5)\"]\n",
    "    session_name = \"Vespertino\" if session == \"V\" else \"Matutino\"\n",
    "    sheet = workbook.active\n",
    "\n",
    "    for filename, (timestamps, data, file_path) in data_per_file.items():\n",
    "        color = get_color_for_file(filename)  # Color basado en el sufijo del archivo\n",
    "\n",
    "        # Determinar las subcarpetas Baseline o Experimental Color\n",
    "        if \"mednegra.txt\" in filename:\n",
    "            subfolder = \"Baseline\"\n",
    "        else:\n",
    "            subfolder = \"Experimental Color\"\n",
    "\n",
    "        pdf_file = os.path.join(output_pdf_folder, subfolder, f\"{filename}.pdf\")\n",
    "        img_file = os.path.join(output_img_folder, subfolder, f\"{filename}.png\")\n",
    "\n",
    "        with PdfPages(pdf_file) as pdf:\n",
    "            if lab in n_change:\n",
    "                n_lab = n_change[lab]\n",
    "            fig, axes = plt.subplots(6, 3, figsize=(36, 45))  # Tamaño más grande de la figura\n",
    "            fig.subplots_adjust(top=0.85, wspace=0.6)  # Más espacio entre columnas, se puede modificar wspace para ajustar el espacio\n",
    "            fig.suptitle(f\"Análisis del archivo: {filename}\\n\"\n",
    "                         f\"Laboratorio: {n_lab}, Turno: {session_name}, Fecha: {date}\", fontsize=40, y=0.98)  # Título más grande\n",
    "            axes = axes.flatten()\n",
    "            stats = generate_statistics(data)  # Generar estadísticas una vez por archivo\n",
    "            stats_formatted = format_statistics(stats, fmt=\".10f\")\n",
    "\n",
    "            for i in range(6):\n",
    "                # Gráfico de Datos Crudos\n",
    "                ax = axes[3 * i]\n",
    "                ax.plot(data[i], label='Datos', color=color)\n",
    "                ax.set_title(f\"Componente {component_names[i]} - Datos Crudos\", fontsize=27)  # Títulos más grandes\n",
    "                ax.set_xlabel(\"Registros\", fontsize=25)\n",
    "                ax.set_ylabel(\"Volts\", fontsize=25)\n",
    "                ax.legend()\n",
    "                ax.tick_params(axis='x', rotation=45, labelsize=25)  # Tamaño de las etiquetas de los ejes x y y\n",
    "                ax.tick_params(axis='y', labelsize=25)  # Tamaño de las etiquetas de los ejes y\n",
    "\n",
    "                # Histograma de Derivadas\n",
    "                derivative = np.gradient(data[i])\n",
    "                ax_hist = axes[3 * i + 1]\n",
    "                ax_hist.hist(derivative, bins=25, color=color, edgecolor='black')\n",
    "                ax_hist.set_title(f\"Componente {component_names[i]} - Histograma de Derivadas\", fontsize=27)\n",
    "                ax_hist.set_xlabel(\"Valor de la Derivada\", fontsize=25)\n",
    "                ax_hist.set_ylabel(\"Frecuencia\", fontsize=25)\n",
    "                ax_hist.tick_params(axis='x', labelsize=25)  # Tamaño de las etiquetas de los ejes x\n",
    "                ax_hist.tick_params(axis='y', labelsize=25)  # Tamaño de las etiquetas de los ejes y\n",
    "\n",
    "                # Texto de Estadísticas de Datos Crudos\n",
    "                stats_text = (f\"Media: {stats_formatted['mean'][i]}\\n\"\n",
    "                              f\"Mediana: {stats_formatted['median'][i]}\\n\"\n",
    "                              f\"Varianza: {stats_formatted['variance'][i]}\\n\"\n",
    "                              f\"Desviación Estándar: {stats_formatted['stdDev'][i]}\\n\"\n",
    "                              f\"Mínimo: {stats_formatted['min'][i]}\\n\"\n",
    "                              f\"Máximo: {stats_formatted['max'][i]}\\n\"\n",
    "                              f\"Primer Cuartil: {stats_formatted['firstQuartile'][i]}\\n\"\n",
    "                              f\"Tercer Cuartil: {stats_formatted['thirdQuartile'][i]}\\n\"\n",
    "                              f\"IQR: {stats_formatted['iqr'][i]}\\n\"\n",
    "                              f\"Varianza Recortada: {stats_formatted['trimmedVariance'][i]}\\n\"\n",
    "                              f\"Kurtosis: {stats_formatted['kurtosis'][i]}\\n\"\n",
    "                              f\"Asimetría: {stats_formatted['skewness'][i]}\")\n",
    "                ax_stats = axes[3 * i + 2]\n",
    "                ax_stats.text(0.1, 0.5, stats_text, fontsize=25, verticalalignment='center')\n",
    "                ax_stats.axis('off')\n",
    "                ax_stats.set_title(f\"Componente {component_names[i]} - Estadísticas de Datos Crudos\", fontsize=24)\n",
    "\n",
    "            plt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajusta el espacio de toda la figura\n",
    "            pdf.savefig(fig)  # Guarda el gráfico en el PDF\n",
    "            plt.savefig(img_file, dpi=400)  # Guarda el gráfico como imagen de alta calidad\n",
    "            plt.close()\n",
    "\n",
    "            # Añadir datos al Excel\n",
    "            add_data_to_excel(sheet, stats_formatted, date, session_name, filename, lab)\n",
    "\n",
    "        # Generar archivo de texto con las estadísticas\n",
    "        text_folder = os.path.join(output_text_folder, subfolder)\n",
    "        stats_file = os.path.join(text_folder, f\"{filename}.txt\")\n",
    "        os.makedirs(os.path.dirname(stats_file), exist_ok=True)\n",
    "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(f\"{date},{session_name},{filename}\\n\\n\")\n",
    "            for i, component in enumerate(component_names):\n",
    "                f.write(f\"{component}\\n\")\n",
    "                f.write(f\"{stats_formatted['median'][i]},{stats_formatted['mean'][i]},{stats_formatted['variance'][i]},{stats_formatted['stdDev'][i]},{stats_formatted['min'][i]},{stats_formatted['max'][i]},{stats_formatted['firstQuartile'][i]},{stats_formatted['thirdQuartile'][i]},{stats_formatted['iqr'][i]},{stats_formatted['trimmedVariance'][i]},{stats_formatted['kurtosis'][i]},{stats_formatted['skewness'][i]}\\n\\n\")\n",
    "\n",
    "# Función para añadir datos al Excel\n",
    "def add_data_to_excel(sheet, stats_formatted, date, session_name, filename, lab):\n",
    "    component_names = [\"FRONT(A0)\", \"REAR(A1)\", \"LEFT(A2)\", \"RIGHT(A3)\", \"TOP(A4)\", \"BOTTOM(A5)\"]\n",
    "    row_data = [date, session_name, lab, filename]  # Incluyendo el nombre del laboratorio\n",
    "\n",
    "    for i in range(6):\n",
    "        row_data.extend([\n",
    "            stats_formatted['median'][i], stats_formatted['mean'][i], stats_formatted['variance'][i],\n",
    "            stats_formatted['stdDev'][i], stats_formatted['min'][i], stats_formatted['max'][i],\n",
    "            stats_formatted['firstQuartile'][i], stats_formatted['thirdQuartile'][i], stats_formatted['iqr'][i],\n",
    "            stats_formatted['trimmedVariance'][i], stats_formatted['kurtosis'][i], stats_formatted['skewness'][i]\n",
    "        ])\n",
    "        row_data.append(\"\")  # Espacio entre componentes\n",
    "\n",
    "    sheet.append(row_data)\n",
    "\n",
    "# Función para procesar todos los experimentos\n",
    "def process_all_experiments(root_folder):\n",
    "    date = extract_date_from_root_folder(root_folder)\n",
    "    date = date.replace(\"- copia\", \"\").strip()\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    sessions = [\"V\", \"M\"]\n",
    "\n",
    "    # Creando un nuevo libro de trabajo y hoja\n",
    "    workbook = openpyxl.Workbook()\n",
    "    sheet = workbook.active\n",
    "    sheet.title = \"Datos\"\n",
    "\n",
    "    # Añadiendo la fila de títulos\n",
    "    titles = [\n",
    "        \"DATE\", \"SHIFT\", \"LAB\", \"FILENAME\",\n",
    "        \"General Statistics FRONT\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n",
    "        \"General Statistics REAR\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n",
    "        \"General Statistics LEFT\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n",
    "        \"General Statistics RIGHT\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n",
    "        \"General Statistics TOP\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\",\n",
    "        \"General Statistics BOTTOM\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"\n",
    "    ]\n",
    "    sheet.append(titles)\n",
    "\n",
    "    # Añadiendo subtítulos\n",
    "    subtitles = [\n",
    "        \"\", \"\", \"\", \"\",\n",
    "        \"Median\", \"Mean\", \"Variance\", \"STD\", \"Min\", \"Max\", \"First Quartile\", \"Third Quartile\", \"IQR\", \"Trimmed Variance (0.2)\", \"Kurtosis\", \"Skewness\", \"\",\n",
    "        \"Median\", \"Mean\", \"Variance\", \"STD\", \"Min\", \"Max\", \"First Quartile\", \"Third Quartile\", \"IQR\", \"Trimmed Variance (0.2)\", \"Kurtosis\", \"Skewness\", \"\",\n",
    "        \"Median\", \"Mean\", \"Variance\", \"STD\", \"Min\", \"Max\", \"First Quartile\", \"Third Quartile\", \"IQR\", \"Trimmed Variance (0.2)\", \"Kurtosis\", \"Skewness\", \"\",\n",
    "        \"Median\", \"Mean\", \"Variance\", \"STD\", \"Min\", \"Max\", \"First Quartile\", \"Third Quartile\", \"IQR\", \"Trimmed Variance (0.2)\", \"Kurtosis\", \"Skewness\", \"\",\n",
    "        \"Median\", \"Mean\", \"Variance\", \"STD\", \"Min\", \"Max\", \"First Quartile\", \"Third Quartile\", \"IQR\", \"Trimmed Variance (0.2)\", \"Kurtosis\", \"Skewness\", \"\",\n",
    "        \"Median\", \"Mean\", \"Variance\", \"STD\", \"Min\", \"Max\", \"First Quartile\", \"Third Quartile\", \"IQR\", \"Trimmed Variance (0.2)\", \"Kurtosis\", \"Skewness\", \"\"\n",
    "    ]\n",
    "    sheet.append(subtitles)\n",
    "\n",
    "    for lab in labs:\n",
    "        for session in sessions:\n",
    "            experiment_folder = os.path.join(root_folder, f\"{date} - {lab}\", f\"{date}.{session} - {lab}\")\n",
    "            print(f\"Checking directory: {experiment_folder}\")\n",
    "            if os.path.exists(experiment_folder):\n",
    "                output_pdf_folder = os.path.join(experiment_folder, \"Data Analysis\", \"Graphics\", \"General Statistics\", \"PDFs\")\n",
    "                output_img_folder = os.path.join(experiment_folder, \"Data Analysis\", \"Graphics\", \"General Statistics\", \"Images\")\n",
    "                output_text_folder = os.path.join(experiment_folder, \"Data Analysis\", \"Processing Data\", \"General Statistics Text\")\n",
    "                os.makedirs(output_pdf_folder, exist_ok=True)\n",
    "                os.makedirs(output_img_folder, exist_ok=True)\n",
    "                os.makedirs(output_text_folder, exist_ok=True)\n",
    "\n",
    "                # Crear subcarpetas Baseline y Experimental Color\n",
    "                os.makedirs(os.path.join(output_pdf_folder, \"Baseline\"), exist_ok=True)\n",
    "                os.makedirs(os.path.join(output_pdf_folder, \"Experimental Color\"), exist_ok=True)\n",
    "                os.makedirs(os.path.join(output_img_folder, \"Baseline\"), exist_ok=True)\n",
    "                os.makedirs(os.path.join(output_img_folder, \"Experimental Color\"), exist_ok=True)\n",
    "                os.makedirs(os.path.join(output_text_folder, \"Baseline\"), exist_ok=True)\n",
    "                os.makedirs(os.path.join(output_text_folder, \"Experimental Color\"), exist_ok=True)\n",
    "\n",
    "                data_per_file = analyze_folder(experiment_folder)\n",
    "                plot_comparison_grid(data_per_file, output_pdf_folder, output_img_folder, output_text_folder, lab, session, date, workbook)\n",
    "            else:\n",
    "                print(f\"Directory does not exist: {experiment_folder}\")\n",
    "\n",
    "    # Ruta de salida del archivo Excel\n",
    "    excel_output_path = os.path.join(root_folder, f\"General_Statistics_{date}.xlsx\")\n",
    "\n",
    "    # Asegurarse de que el directorio existe antes de guardar\n",
    "    os.makedirs(root_folder, exist_ok=True)\n",
    "\n",
    "    # Guardando el archivo Excel al final de todos los experimentos\n",
    "    workbook.save(excel_output_path)\n",
    "    print(\"Archivo Excel generado exitosamente en:\", excel_output_path)\n",
    "\n",
    "# Cambia la ruta de root_folder a la que corresponde a tu directorio raíz\n",
    "\n",
    "process_all_experiments(root_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "$$\n",
    "\\Huge \\text{Boxplots}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplots\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import iqr\n",
    "import re\n",
    "\n",
    "def read_sensor_data(filepath):\n",
    "    data = []\n",
    "    timestamps = []\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(' -> ')\n",
    "                if len(parts) > 1:\n",
    "                    timestamps.append(parts[0])\n",
    "                    numbers = parts[1].strip('()').split(', ')\n",
    "                    data.append([float(num) for num in numbers])\n",
    "        return timestamps, np.array(data).T\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el archivo {filepath}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calibrate_sensor(data, filename):\n",
    "    try:\n",
    "        results = {\n",
    "            'mean': np.mean(data, axis=1),\n",
    "            'median': np.median(data, axis=1),\n",
    "            'variance': np.var(data, axis=1),\n",
    "            'stdDev': np.std(data, axis=1),\n",
    "            'min': np.min(data, axis=1),\n",
    "            'max': np.max(data, axis=1),\n",
    "            'firstQuartile': np.percentile(data, 25, axis=1),\n",
    "            'thirdQuartile': np.percentile(data, 75, axis=1),\n",
    "            'iqr': iqr(data, axis=1),\n",
    "            'trimmedVariance': [np.var(np.trim_zeros(np.sort(sensor_data))) for sensor_data in data]\n",
    "        }\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cacular estadisticas los datos, REVISAR ARCHIVO: {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_experiment_folder(root_folder, lab, session):\n",
    "    # Expresión regular para buscar carpetas con formato de fecha\n",
    "    date_regex = re.compile(r'\\d{2}[A-Za-z]{3}\\d{2}')\n",
    "    msg_error = 'no se hayó la carpeta'\n",
    "    for folder in os.listdir(root_folder):\n",
    "        if date_regex.search(folder) and lab in folder:\n",
    "            for subfolder in os.listdir(os.path.join(root_folder, folder)):\n",
    "                if date_regex.search(subfolder) and session in subfolder:\n",
    "                    return os.path.join(root_folder, folder, subfolder)\n",
    "    return msg_error\n",
    "\n",
    "\n",
    "\n",
    "# Función para generar boxplots\n",
    "def generate_boxplot(data, filename, output_folder, lab, session):\n",
    "    labels = [\"Frontal\", \"Rear\", \"Left\", \"Right\", \"Top\", \"Bottom\"]\n",
    "    color_dict = {\n",
    "        'negra': 'black',\n",
    "        'roja': 'red',\n",
    "        'morada': 'purple',\n",
    "        'azul': 'blue',\n",
    "        'verde': 'green',\n",
    "        'amarilla': 'yellow'\n",
    "    }\n",
    "    file_base_name = filename.split('.')[0]  # Remove extension\n",
    "    color_suffix = file_base_name.split('med')[-1]\n",
    "    color = color_dict.get(color_suffix, 'gray')  # Default color if not matched\n",
    "    if lab in n_change:\n",
    "      n_lab = n_change[lab]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot(data.T, notch=True, patch_artist=True, boxprops=dict(facecolor=color))\n",
    "    plt.title(f'Box Plot for {filename} - {n_lab} - {session}')\n",
    "    plt.xlabel('Side of Cube')\n",
    "    plt.ylabel('Volts')\n",
    "    plt.xticks(range(1, len(labels) + 1), labels, rotation=45)\n",
    "    plt.savefig(os.path.join(output_folder, f\"{file_base_name}_{lab}_{session}_boxplot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Función para generar boxplots de comparación\n",
    "def generate_comparison_boxplot(data_a, data_b, filename, output_folder, session, color_a, color_b):\n",
    "    labels = [\"Frontal\", \"Rear\", \"Left\", \"Right\", \"Top\", \"Bottom\"]\n",
    "    combined_data = [data_a[i] for i in range(data_a.shape[0])] + [data_b[i] for i in range(data_b.shape[0])]\n",
    "    positions = list(range(1, data_a.shape[0] + 1)) + list(range(data_a.shape[0] + 2, data_a.shape[0] + data_b.shape[0] + 2))\n",
    "    colors = [color_a] * data_a.shape[0] + [color_b] * data_b.shape[0]\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    boxprops = dict(facecolor='white')  # Default color\n",
    "    bplots = plt.boxplot(combined_data, positions=positions, notch=True, patch_artist=True, boxprops=boxprops)\n",
    "\n",
    "    for patch, color in zip(bplots['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    plt.title(f'Comparison Box Plot for {filename} - {session}\\nLab_Betta (left) vs Lab_Gamma (right)')\n",
    "    plt.xlabel('Side of Cube')\n",
    "    plt.ylabel('Volts')\n",
    "    plt.xticks(range(1, len(labels) * 2 + 1), labels * 2, rotation=45)\n",
    "    plt.legend(handles=[plt.Line2D([0], [0], color=color_a, lw=4, label='Lab_Betta'),\n",
    "                        plt.Line2D([0], [0], color=color_b, lw=4, label='Lab_Gamma')],\n",
    "               labels=['Lab_Betta', 'Lab_Gamma'], loc='upper center', bbox_to_anchor=(0.5, -0.05), fancybox=True, shadow=True, ncol=2)\n",
    "    plt.savefig(os.path.join(output_folder, f\"{filename}_comparison_{session}_boxplot.png\"))\n",
    "    plt.close()\n",
    "\n",
    "# Función para analizar las carpetas\n",
    "def analyze_folder(folder_path, output_folder, lab, session):\n",
    "    file_stats = {}\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for filename in files:\n",
    "            if any(filename.startswith(\"0\") and filename.endswith(ext) for ext in [\"mednegra.txt\", \"medroja.txt\", \"medmorada.txt\", \"medazul.txt\", \"medverde.txt\", \"medamarilla.txt\"]):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                timestamps, data = read_sensor_data(file_path)\n",
    "                if data is not None:\n",
    "                    stats = calibrate_sensor(data, filename)\n",
    "                    if stats is not None:\n",
    "                        file_stats[filename] = {'stats': stats, 'data': data}\n",
    "                        generate_boxplot(data, filename, output_folder, lab, session)\n",
    "    return file_stats\n",
    "\n",
    "\n",
    "# Función para procesar todos los experimentos\n",
    "def process_all_experiments(root_folder):\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    sessions = [\"V\", \"M\"]\n",
    "    all_data = {session: {lab: {} for lab in labs} for session in sessions}\n",
    "    global_output_folder = os.path.join(root_folder, \"Data Analysis\", \"Global Comparisons\")\n",
    "    os.makedirs(global_output_folder, exist_ok=True)\n",
    "\n",
    "    for lab in labs:\n",
    "        for session in sessions:\n",
    "            experiment_folder = find_experiment_folder(root_folder, lab, session)\n",
    "            if os.path.exists(experiment_folder):\n",
    "                output_folder_base = os.path.join(experiment_folder, \"Data Analysis\", \"Graphics\")\n",
    "                function_title = \"Boxplots\"\n",
    "                output_folder = os.path.join(output_folder_base, function_title)\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "                file_stats = analyze_folder(experiment_folder, output_folder, lab, session)\n",
    "                all_data[session][lab] = file_stats\n",
    "\n",
    "    color_dict = {\n",
    "        'negra': 'black',\n",
    "        'roja': 'red',\n",
    "        'morada': 'purple',\n",
    "        'azul': 'blue',\n",
    "        'verde': 'green',\n",
    "        'amarilla': 'yellow'\n",
    "    }\n",
    "\n",
    "    # Generar comparaciones globales\n",
    "    for session in sessions:\n",
    "        for filename in all_data[session][\"Lab_Betta\"]:\n",
    "            if filename in all_data[session][\"Lab_Gamma\"]:\n",
    "                data_a = all_data[session][\"Lab_Betta\"][filename]['data']\n",
    "                data_b = all_data[session][\"Lab_Gamma\"][filename]['data']\n",
    "                color_suffix_a = filename.split('med')[-1].split('.')[0]\n",
    "                color_suffix_b = filename.split('med')[-1].split('.')[0]\n",
    "                color_a = color_dict.get(color_suffix_a, 'blue')\n",
    "                color_b = color_dict.get(color_suffix_b, 'green')\n",
    "                generate_comparison_boxplot(data_a, data_b, filename, global_output_folder, session, color_a, color_b)\n",
    "\n",
    "# Procesar todos los experimentos\n",
    "\n",
    "process_all_experiments(root_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\n",
    "$$\n",
    "\\Huge \\text{First Integer Helicity Betta vs Gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitiendo cálculo para Lab_Betta V ya que el directorio no existe.\n",
      "Omitiendo cálculo para Lab_Gamma V ya que el directorio no existe.\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLT_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRT_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\RTB_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\LTB_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLB_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLB_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLT_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRT_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRB_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\RTB_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRT_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRT_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRP_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRB_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\RTB_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRT_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLB_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRB_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRB_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLB_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLB_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLP_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRP_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\LTB_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLT_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLB_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLB_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLP_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRB_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLT_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLB_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLT_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRP_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLT_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRT_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRB_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRB_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRP_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\LTB_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\LTB_velocity\\Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FRB_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PLT_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRT_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLT_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLP_velocity\\Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\FLP_velocity\\Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\RTB_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Helicity_Comp\\PRT_velocity\\Helicity_Comparison_04_05_04_04_05_04.png\n"
     ]
    }
   ],
   "source": [
    "#Grafica Integral Helicidad Betta vs Gamma\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Diccionario de triadas y códigos\n",
    "triad_codes = {\n",
    "    (0, 2, 4): \"FRT\",  \n",
    "    (1, 3, 5): \"PLB\",  \n",
    "    (0, 3, 4): \"FLT\",  \n",
    "    (1, 2, 5): \"PRB\",  \n",
    "    (0, 2, 5): \"FRB\",  \n",
    "    (1, 3, 4): \"PLT\",  \n",
    "    (0, 3, 5): \"FLB\",  \n",
    "    (1, 2, 4): \"PRT\",  \n",
    "    (2, 4, 5): \"RTB\",  \n",
    "    (0, 1, 3): \"FLP\",  \n",
    "    (3, 4, 5): \"LTB\",  \n",
    "    (0, 1, 2): \"FRP\"\n",
    "}\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'velocity_(\\d+)med', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def read_data(filepath):\n",
    "    timestamps = []\n",
    "    values = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                timestamps.append(timestamp)\n",
    "                values.append(float(parts[1]))\n",
    "    return timestamps, np.array(values)\n",
    "\n",
    "def get_color(filename):\n",
    "    color_map = {\n",
    "        'medroja.txt': 'red',\n",
    "        'medmorada.txt': 'purple',\n",
    "        'medazul.txt': 'blue',\n",
    "        'medverde.txt': 'green',\n",
    "        'medamarilla.txt': 'yellow',\n",
    "        'mednaranja.txt': 'orange'\n",
    "    }\n",
    "    for suffix, color in color_map.items():\n",
    "        if suffix in filename:\n",
    "            return color\n",
    "    return 'gray'  # Default color if no match found\n",
    "\n",
    "# Diccionario de nombres de triadas\n",
    "triad_names = {\n",
    "    \"FRT\": \"Frontal-Derecho-Superior\",  \n",
    "    \"PLB\": \"Trasero-Izquierdo-Inferior\",  \n",
    "    \"FLT\": \"Frontal-Izquierdo-Superior\",  \n",
    "    \"PRB\": \"Trasero-Derecho-Inferior\",  \n",
    "    \"FRB\": \"Frontal-Derecho-Inferior\",  \n",
    "    \"PLT\": \"Trasero-Izquierdo-Superior\",  \n",
    "    \"FLB\": \"Frontal-Izquierdo-Inferior\",  \n",
    "    \"PRT\": \"Trasero-Derecho-Superior\",  \n",
    "    \"RTB\": \"Derecho-Superior-Inferior\",  \n",
    "    \"FLP\": \"Frontal-Izquierdo-Trasero\",  \n",
    "    \"LTB\": \"Izquierdo-Superior-Inferior\",  \n",
    "    \"FRP\": \"Frontal-Derecho-Trasero\"\n",
    "}\n",
    "\n",
    "def plot_comparison(base_file1_betta, base_file2_betta, experimental_file_betta,\n",
    "                    base_file1_gamma, base_file2_gamma, experimental_file_gamma,\n",
    "                    output_dir, shift, date_str):\n",
    "    # Leer los datos de Lab_Betta\n",
    "    timestamps_base1_betta, base_values1_betta = read_data(base_file1_betta)\n",
    "    timestamps_base2_betta, base_values2_betta = read_data(base_file2_betta)\n",
    "    timestamps_experimental_betta, experimental_values_betta = read_data(experimental_file_betta)\n",
    "\n",
    "    # Leer los datos de Lab_Gamma\n",
    "    timestamps_base1_gamma, base_values1_gamma = read_data(base_file1_gamma)\n",
    "    timestamps_base2_gamma, base_values2_gamma = read_data(base_file2_gamma)\n",
    "    timestamps_experimental_gamma, experimental_values_gamma = read_data(experimental_file_gamma)\n",
    "\n",
    "    # Reiniciar todas las estampas de tiempo para Lab_Betta\n",
    "    start_time_base1_betta = timestamps_base1_betta[0]\n",
    "    start_time_base2_betta = timestamps_base2_betta[0]\n",
    "    start_time_experimental_betta = timestamps_experimental_betta[0]\n",
    "    timestamps_base1_betta = [(ts - start_time_base1_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_base1_betta]\n",
    "    timestamps_base2_betta = [(ts - start_time_base2_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_base2_betta]\n",
    "    timestamps_experimental_betta = [(ts - start_time_experimental_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_experimental_betta]\n",
    "\n",
    "    # Reiniciar todas las estampas de tiempo para Lab_Gamma\n",
    "    start_time_base1_gamma = timestamps_base1_gamma[0]\n",
    "    start_time_base2_gamma = timestamps_base2_gamma[0]\n",
    "    start_time_experimental_gamma = timestamps_experimental_gamma[0]\n",
    "    timestamps_base1_gamma = [(ts - start_time_base1_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_base1_gamma]\n",
    "    timestamps_base2_gamma = [(ts - start_time_base2_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_base2_gamma]\n",
    "    timestamps_experimental_gamma = [(ts - start_time_experimental_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_experimental_gamma]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    base_times1_betta = mdates.date2num(timestamps_base1_betta)\n",
    "    base_times2_betta = mdates.date2num(timestamps_base2_betta)\n",
    "    experimental_times_betta = mdates.date2num(timestamps_experimental_betta)\n",
    "\n",
    "    base_times1_gamma = mdates.date2num(timestamps_base1_gamma)\n",
    "    base_times2_gamma = mdates.date2num(timestamps_base2_gamma)\n",
    "    experimental_times_gamma = mdates.date2num(timestamps_experimental_gamma)\n",
    "    \n",
    "    # Obtener las triadas para los títulos\n",
    "    triada_betta = extract_triada(experimental_file_betta)\n",
    "    triada_gamma = extract_triada(experimental_file_gamma)\n",
    "\n",
    "    # Usar los nombres descriptivos de las triadas en los títulos\n",
    "    triad_name_betta = triad_names.get(triada_betta, triada_betta)\n",
    "    triad_name_gamma = triad_names.get(triada_gamma, triada_gamma)\n",
    "\n",
    "    # Lab_Betta gráfico\n",
    "    ax1.plot(base_times1_betta, base_values1_betta, c='black', label=os.path.basename(base_file1_betta))\n",
    "    ax1.plot(base_times2_betta, base_values2_betta, c='gray', label=os.path.basename(base_file2_betta))\n",
    "    ax1.plot(experimental_times_betta, experimental_values_betta, c=get_color(experimental_file_betta), label=os.path.basename(experimental_file_betta))\n",
    "    ax1.set_title(f'Lab_Betta - {shift} - Date: {date_str} - {triad_name_betta}', fontsize=14)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Lab_Gamma gráfico\n",
    "    ax2.plot(base_times1_gamma, base_values1_gamma, c='black', label=os.path.basename(base_file1_gamma))\n",
    "    ax2.plot(base_times2_gamma, base_values2_gamma, c='gray', label=os.path.basename(base_file2_gamma))\n",
    "    ax2.plot(experimental_times_gamma, experimental_values_gamma, c=get_color(experimental_file_gamma), label=os.path.basename(experimental_file_gamma))\n",
    "    ax2.set_title(f'Lab_Gamma - {shift} - Date: {date_str} - {triad_name_gamma}', fontsize=14)\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.legend()\n",
    "    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Generar un nombre más corto para cada gráfico\n",
    "    number1_betta = extract_number(base_file1_betta)\n",
    "    number2_betta = extract_number(base_file2_betta)\n",
    "    number_exp_betta = extract_number(experimental_file_betta)\n",
    "    number1_gamma = extract_number(base_file1_gamma)\n",
    "    number2_gamma = extract_number(base_file2_gamma)\n",
    "    number_exp_gamma = extract_number(experimental_file_gamma)\n",
    "\n",
    "    output_filename = (f\"Helicity_Comparison_{number1_betta}_{number2_betta}_{number_exp_betta}_\"\n",
    "                   f\"{number1_gamma}_{number2_gamma}_{number_exp_gamma}.png\")\n",
    "\n",
    "    # Determinar la carpeta de salida en función del código de triada del archivo experimental de Lab_Betta\n",
    "    triad_code_betta = re.search(r'helicity_(\\w+)_', experimental_file_betta)\n",
    "    if triad_code_betta:\n",
    "        triad_code_betta = triad_code_betta.group(1)\n",
    "        specific_output_dir = os.path.join(output_dir, triad_code_betta)\n",
    "    else:\n",
    "        specific_output_dir = output_dir\n",
    "\n",
    "    if not os.path.exists(specific_output_dir):\n",
    "        os.makedirs(specific_output_dir)\n",
    "\n",
    "    output_filepath = os.path.join(specific_output_dir, output_filename)\n",
    "    plt.savefig(output_filepath)\n",
    "    print(f\"Saved plot as {output_filepath}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def generate_combinations(baseline_files, experimental_files):\n",
    "    combinations = []\n",
    "    # Extraer triadas de los nombres de los archivos\n",
    "    baseline_triads = set()\n",
    "    experimental_triads = set()\n",
    "\n",
    "    for f in baseline_files:\n",
    "        match = re.search(r'helicity_(\\w+)_', f)\n",
    "        if match:\n",
    "            baseline_triads.add(match.group(1))\n",
    "\n",
    "    for f in experimental_files:\n",
    "        match = re.search(r'helicity_(\\w+)_', f)\n",
    "        if match:\n",
    "            experimental_triads.add(match.group(1))\n",
    "\n",
    "    # Generar combinaciones solo para triadas comunes\n",
    "    common_triads = baseline_triads.intersection(experimental_triads)\n",
    "    for triad in common_triads:\n",
    "        baseline_files_for_triad = [f for f in baseline_files if f\"helicity_{triad}_\" in f]\n",
    "        experimental_files_for_triad = [f for f in experimental_files if f\"helicity_{triad}_\" in f]\n",
    "        \n",
    "        # Asegurarse de que hay al menos dos archivos base para cada triada\n",
    "        if len(baseline_files_for_triad) >= 2:\n",
    "            for i, base_file1 in enumerate(baseline_files_for_triad):\n",
    "                for base_file2 in baseline_files_for_triad[i+1:]:\n",
    "                    for exp_file in experimental_files_for_triad:\n",
    "                        number1 = int(extract_number(base_file1))\n",
    "                        number2 = int(extract_number(base_file2))\n",
    "                        number_exp = int(extract_number(exp_file))\n",
    "                        if number1 == number_exp == ((number2)-1):\n",
    "                            combinations.append((base_file1, base_file2, exp_file))\n",
    "    return combinations\n",
    "\n",
    "def extract_triada(ruta):\n",
    "    # Extrae el nombre del archivo de la ruta\n",
    "    nombre_archivo = os.path.basename(ruta)\n",
    "    \n",
    "    # Busca y extrae la triada\n",
    "    match_triada = re.search(r'(FLB|FRP|PLB|PRB|FRT|PRT|FLT|PLT|RTB|LTB|FRB|FLP)', nombre_archivo)\n",
    "    triada = match_triada.group(1) if match_triada else None\n",
    "    \n",
    "    return triada\n",
    "\n",
    "def main():\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    combinations1 = []  # Definir una lista para combinaciones de Lab_Betta\n",
    "    combinations2 = []  # Definir una lista para combinaciones de Lab_Gamma\n",
    "\n",
    "    for lab in labs:\n",
    "        for shift in shifts:\n",
    "            lab_dirs = glob.glob(os.path.join(root_folder, f\"*{lab}\"))\n",
    "            if not lab_dirs:\n",
    "                print(f\"No se encontró ningún directorio para {lab}.\")\n",
    "                continue\n",
    "            lab_dir = lab_dirs[0]\n",
    "            date_str = os.path.basename(lab_dir).split(' ')[0]\n",
    "\n",
    "            baseline_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Sum_Helicity_Baseline\")\n",
    "            exp_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Sum_Helicity_Experimental_Color\")\n",
    "            output_directory = os.path.join(root_folder, \"Data Analysis\", \"Graphics\", \"Sum_Helicity_Comp\")\n",
    "\n",
    "            if not os.path.exists(baseline_dir) or not os.path.exists(exp_dir):\n",
    "                print(f\"Omitiendo cálculo para {lab} {shift} ya que el directorio no existe.\")\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(output_directory):\n",
    "                os.makedirs(output_directory)\n",
    "\n",
    "            # Buscar en subcarpetas de triadas\n",
    "            baseline_files = []\n",
    "            experimental_files = []\n",
    "\n",
    "            for triad_code in triad_codes.values():\n",
    "                # Buscar en subcarpetas basadas en triad_codes\n",
    "                baseline_files.extend(glob.glob(os.path.join(baseline_dir, triad_code, 'sum_helicity_*mednegra.txt')))\n",
    "                experimental_files.extend(glob.glob(os.path.join(exp_dir, triad_code, 'sum_helicity_*med*.txt')))\n",
    "\n",
    "            if lab == \"Lab_Betta\":\n",
    "                combinations1 = generate_combinations(baseline_files, experimental_files)\n",
    "                combinations1 = list(set(combinations1))\n",
    "            else:\n",
    "                combinations2 = generate_combinations(baseline_files, experimental_files)\n",
    "                combinations2 = list(set(combinations2))\n",
    "\n",
    "    for base_file1_betta, base_file2_betta, experimental_file_betta in combinations1:\n",
    "        for base_file1_gamma, base_file2_gamma, experimental_file_gamma in combinations2:\n",
    "            number1_betta = extract_number(base_file1_betta)\n",
    "            number2_betta = extract_number(base_file2_betta)\n",
    "            number_exp_betta = extract_number(experimental_file_betta)\n",
    "            number1_gamma = extract_number(base_file1_gamma)\n",
    "            number2_gamma = extract_number(base_file2_gamma)\n",
    "            number_exp_gamma = extract_number(experimental_file_gamma)\n",
    "            triada1_betta = extract_triada(base_file1_betta)\n",
    "            triada2_betta = extract_triada(base_file2_betta)\n",
    "            triada_exp_betta = extract_triada(experimental_file_betta)\n",
    "            triada1_gamma = extract_triada(base_file1_gamma)\n",
    "            triada2_gamma = extract_triada(base_file1_gamma)\n",
    "            triada_exp_gamma = extract_triada(experimental_file_gamma)\n",
    "            \n",
    "            if (number1_betta == number1_gamma and number2_betta == number2_gamma and number_exp_betta == number_exp_gamma and \n",
    "                triada1_betta == triada2_betta == triada_exp_betta and \n",
    "                triada1_gamma == triada2_gamma == triada_exp_gamma and \n",
    "                triada1_betta == triada1_gamma and \n",
    "                triada2_betta == triada2_gamma and \n",
    "                triada_exp_betta == triada_exp_gamma):\n",
    "                plot_comparison(base_file1_betta, base_file2_betta, experimental_file_betta,\n",
    "                            base_file1_gamma, base_file2_gamma, experimental_file_gamma,\n",
    "                            output_directory, shift, date_str)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## 4 \n",
    "$$\n",
    "\\Huge \\text{Sum Absolute Helicity Betta vs Gamma}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitiendo cálculo para Lab_Betta V ya que el directorio no existe.\n",
      "Omitiendo cálculo para Lab_Gamma V ya que el directorio no existe.\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLT_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLT_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLB_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\LTB_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLB_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLP_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRT_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRT_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRB_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLB_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\RTB_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRT_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLB_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLB_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLT_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRP_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLP_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRB_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLT_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRT_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLP_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLT_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\RTB_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLB_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRP_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRB_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLB_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRT_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\RTB_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FLP_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\RTB_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLB_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRT_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRT_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRT_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRB_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\LTB_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\LTB_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRB_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRP_velocity\\Sum_Helicity_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLT_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\LTB_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLT_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRB_velocity\\Sum_Helicity_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PLT_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRP_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\FRB_velocity\\Sum_Helicity_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Absolute_Helicity_Comp\\PRB_velocity\\Sum_Helicity_Comparison_04_05_04_04_05_04.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Diccionario de triadas y códigos\n",
    "triad_codes = {\n",
    "    (0, 2, 4): \"FRT\",  \n",
    "    (1, 3, 5): \"PLB\",  \n",
    "    (0, 3, 4): \"FLT\",  \n",
    "    (1, 2, 5): \"PRB\",  \n",
    "    (0, 2, 5): \"FRB\",  \n",
    "    (1, 3, 4): \"PLT\",  \n",
    "    (0, 3, 5): \"FLB\",  \n",
    "    (1, 2, 4): \"PRT\",  \n",
    "    (2, 4, 5): \"RTB\",  \n",
    "    (0, 1, 3): \"FLP\",  \n",
    "    (3, 4, 5): \"LTB\",  \n",
    "    (0, 1, 2): \"FRP\"\n",
    "}\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'velocity_(\\d+)med', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def read_data(filepath):\n",
    "    timestamps = []\n",
    "    values = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                timestamps.append(timestamp)\n",
    "                values.append(float(parts[1]))\n",
    "    return timestamps, np.array(values)\n",
    "\n",
    "def get_color(filename):\n",
    "    color_map = {\n",
    "        'medroja.txt': 'red',\n",
    "        'medmorada.txt': 'purple',\n",
    "        'medazul.txt': 'blue',\n",
    "        'medverde.txt': 'green',\n",
    "        'medamarilla.txt': 'yellow',\n",
    "        'mednaranja.txt': 'orange'\n",
    "    }\n",
    "    for suffix, color in color_map.items():\n",
    "        if suffix in filename:\n",
    "            return color\n",
    "    return 'gray'  # Default color if no match found\n",
    "\n",
    "# Diccionario de triadas con nombres descriptivos\n",
    "triad_names = {\n",
    "    \"FRT\": \"Frontal-Derecho-Superior\",  \n",
    "    \"PLB\": \"Trasero-Izquierdo-Inferior\",  \n",
    "    \"FLT\": \"Frontal-Izquierdo-Superior\",  \n",
    "    \"PRB\": \"Trasero-Derecho-Inferior\",  \n",
    "    \"FRB\": \"Frontal-Derecho-Inferior\",  \n",
    "    \"PLT\": \"Trasero-Izquierdo-Superior\",  \n",
    "    \"FLB\": \"Frontal-Izquierdo-Inferior\",  \n",
    "    \"PRT\": \"Trasero-Derecho-Superior\",  \n",
    "    \"RTB\": \"Derecho-Superior-Inferior\",  \n",
    "    \"FLP\": \"Frontal-Izquierdo-Trasero\",  \n",
    "    \"LTB\": \"Izquierdo-Superior-Inferior\",  \n",
    "    \"FRP\": \"Frontal-Derecho-Trasero\"\n",
    "}\n",
    "\n",
    "def plot_comparison(base_file1_betta, base_file2_betta, experimental_file_betta,\n",
    "                    base_file1_gamma, base_file2_gamma, experimental_file_gamma,\n",
    "                    output_dir, shift, date_str):\n",
    "    # Leer los datos de Lab_Betta\n",
    "    timestamps_base1_betta, base_values1_betta = read_data(base_file1_betta)\n",
    "    timestamps_base2_betta, base_values2_betta = read_data(base_file2_betta)\n",
    "    timestamps_experimental_betta, experimental_values_betta = read_data(experimental_file_betta)\n",
    "\n",
    "    # Leer los datos de Lab_Gamma\n",
    "    timestamps_base1_gamma, base_values1_gamma = read_data(base_file1_gamma)\n",
    "    timestamps_base2_gamma, base_values2_gamma = read_data(base_file2_gamma)\n",
    "    timestamps_experimental_gamma, experimental_values_gamma = read_data(experimental_file_gamma)\n",
    "\n",
    "    # Reiniciar todas las estampas de tiempo para Lab_Betta\n",
    "    start_time_base1_betta = timestamps_base1_betta[0]\n",
    "    start_time_base2_betta = timestamps_base2_betta[0]\n",
    "    start_time_experimental_betta = timestamps_experimental_betta[0]\n",
    "    timestamps_base1_betta = [(ts - start_time_base1_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_base1_betta]\n",
    "    timestamps_base2_betta = [(ts - start_time_base2_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_base2_betta]\n",
    "    timestamps_experimental_betta = [(ts - start_time_experimental_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_experimental_betta]\n",
    "\n",
    "    # Reiniciar todas las estampas de tiempo para Lab_Gamma\n",
    "    start_time_base1_gamma = timestamps_base1_gamma[0]\n",
    "    start_time_base2_gamma = timestamps_base2_gamma[0]\n",
    "    start_time_experimental_gamma = timestamps_experimental_gamma[0]\n",
    "    timestamps_base1_gamma = [(ts - start_time_base1_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_base1_gamma]\n",
    "    timestamps_base2_gamma = [(ts - start_time_base2_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_base2_gamma]\n",
    "    timestamps_experimental_gamma = [(ts - start_time_experimental_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_experimental_gamma]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    base_times1_betta = mdates.date2num(timestamps_base1_betta)\n",
    "    base_times2_betta = mdates.date2num(timestamps_base2_betta)\n",
    "    experimental_times_betta = mdates.date2num(timestamps_experimental_betta)\n",
    "\n",
    "    base_times1_gamma = mdates.date2num(timestamps_base1_gamma)\n",
    "    base_times2_gamma = mdates.date2num(timestamps_base2_gamma)\n",
    "    experimental_times_gamma = mdates.date2num(timestamps_experimental_gamma)\n",
    "    \n",
    "    # Obtener las triadas para los títulos\n",
    "    triada_betta = extract_triada(experimental_file_betta)\n",
    "    triada_gamma = extract_triada(experimental_file_gamma)\n",
    "\n",
    "    # Usar los nombres descriptivos de las triadas en los títulos\n",
    "    triad_name_betta = triad_names.get(triada_betta, triada_betta)\n",
    "    triad_name_gamma = triad_names.get(triada_gamma, triada_gamma)\n",
    "\n",
    "    # Lab_Betta gráfico\n",
    "    ax1.plot(base_times1_betta, base_values1_betta, c='black', label=os.path.basename(base_file1_betta))\n",
    "    ax1.plot(base_times2_betta, base_values2_betta, c='gray', label=os.path.basename(base_file2_betta))\n",
    "    ax1.plot(experimental_times_betta, experimental_values_betta, c=get_color(experimental_file_betta), label=os.path.basename(experimental_file_betta))\n",
    "    ax1.set_title(f'Lab_Betta - {shift} - Date: {date_str} - {triad_name_betta}', fontsize=14)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Lab_Gamma gráfico\n",
    "    ax2.plot(base_times1_gamma, base_values1_gamma, c='black', label=os.path.basename(base_file1_gamma))\n",
    "    ax2.plot(base_times2_gamma, base_values2_gamma, c='gray', label=os.path.basename(base_file2_gamma))\n",
    "    ax2.plot(experimental_times_gamma, experimental_values_gamma, c=get_color(experimental_file_gamma), label=os.path.basename(experimental_file_gamma))\n",
    "    ax2.set_title(f'Lab_Gamma - {shift} - Date: {date_str} - {triad_name_gamma}', fontsize=14)\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.legend()\n",
    "    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Generar un nombre más corto para cada gráfico\n",
    "    number1_betta = extract_number(base_file1_betta)\n",
    "    number2_betta = extract_number(base_file2_betta)\n",
    "    number_exp_betta = extract_number(experimental_file_betta)\n",
    "    number1_gamma = extract_number(base_file1_gamma)\n",
    "    number2_gamma = extract_number(base_file2_gamma)\n",
    "    number_exp_gamma = extract_number(experimental_file_gamma)\n",
    "\n",
    "    output_filename = (f\"Sum_Helicity_Comparison_{number1_betta}_{number2_betta}_{number_exp_betta}_\"\n",
    "                   f\"{number1_gamma}_{number2_gamma}_{number_exp_gamma}.png\")\n",
    "\n",
    "    # Determinar la carpeta de salida en función del código de triada del archivo experimental de Lab_Betta\n",
    "    triad_code_betta = re.search(r'helicity_(\\w+)_', experimental_file_betta)\n",
    "    if triad_code_betta:\n",
    "        triad_code_betta = triad_code_betta.group(1)\n",
    "        specific_output_dir = os.path.join(output_dir, triad_code_betta)\n",
    "    else:\n",
    "        specific_output_dir = output_dir\n",
    "\n",
    "    if not os.path.exists(specific_output_dir):\n",
    "        os.makedirs(specific_output_dir)\n",
    "\n",
    "    output_filepath = os.path.join(specific_output_dir, output_filename)\n",
    "    plt.savefig(output_filepath)\n",
    "    print(f\"Saved plot as {output_filepath}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def generate_combinations(baseline_files, experimental_files):\n",
    "    combinations = []\n",
    "    # Extraer triadas de los nombres de los archivos\n",
    "    baseline_triads = set()\n",
    "    experimental_triads = set()\n",
    "\n",
    "    for f in baseline_files:\n",
    "        match = re.search(r'helicity_(\\w+)_', f)\n",
    "        if match:\n",
    "            baseline_triads.add(match.group(1))\n",
    "\n",
    "    for f in experimental_files:\n",
    "        match = re.search(r'helicity_(\\w+)_', f)\n",
    "        if match:\n",
    "            experimental_triads.add(match.group(1))\n",
    "\n",
    "    # Generar combinaciones solo para triadas comunes\n",
    "    common_triads = baseline_triads.intersection(experimental_triads)\n",
    "    for triad in common_triads:\n",
    "        baseline_files_for_triad = [f for f in baseline_files if f\"helicity_{triad}_\" in f]\n",
    "        experimental_files_for_triad = [f for f in experimental_files if f\"helicity_{triad}_\" in f]\n",
    "        \n",
    "        # Asegurarse de que hay al menos dos archivos base para cada triada\n",
    "        if len(baseline_files_for_triad) >= 2:\n",
    "            for i, base_file1 in enumerate(baseline_files_for_triad):\n",
    "                for base_file2 in baseline_files_for_triad[i+1:]:\n",
    "                    for exp_file in experimental_files_for_triad:\n",
    "                        number1 = int(extract_number(base_file1))\n",
    "                        number2 = int(extract_number(base_file2))\n",
    "                        number_exp = int(extract_number(exp_file))\n",
    "                        if number1 == number_exp == ((number2)-1):\n",
    "                            combinations.append((base_file1, base_file2, exp_file))\n",
    "    return combinations\n",
    "\n",
    "def extract_triada(ruta):\n",
    "    # Extrae el nombre del archivo de la ruta\n",
    "    nombre_archivo = os.path.basename(ruta)\n",
    "    \n",
    "    # Busca y extrae la triada\n",
    "    match_triada = re.search(r'(FLB|FRP|PLB|PRB|FRT|PRT|FLT|PLT|RTB|LTB|FRB|FLP)', nombre_archivo)\n",
    "    triada = match_triada.group(1) if match_triada else None\n",
    "    \n",
    "    return triada\n",
    "\n",
    "def main():\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    combinations1 = []  # Definir una lista para combinaciones de Lab_Betta\n",
    "    combinations2 = []  # Definir una lista para combinaciones de Lab_Gamma\n",
    "\n",
    "    for lab in labs:\n",
    "        for shift in shifts:\n",
    "            lab_dirs = glob.glob(os.path.join(root_folder, f\"*{lab}\"))\n",
    "            if not lab_dirs:\n",
    "                print(f\"No se encontró ningún directorio para {lab}.\")\n",
    "                continue\n",
    "            lab_dir = lab_dirs[0]\n",
    "            date_str = os.path.basename(lab_dir).split(' ')[0]\n",
    "\n",
    "            baseline_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Sum_Absolute_Helicity_Baseline\")\n",
    "            exp_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Sum_Absolute_Helicity_Experimental_Color\")\n",
    "            output_directory = os.path.join(root_folder, \"Data Analysis\", \"Graphics\", \"Sum_Absolute_Helicity_Comp\")\n",
    "\n",
    "            if not os.path.exists(baseline_dir) or not os.path.exists(exp_dir):\n",
    "                print(f\"Omitiendo cálculo para {lab} {shift} ya que el directorio no existe.\")\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(output_directory):\n",
    "                os.makedirs(output_directory)\n",
    "\n",
    "            # Buscar en subcarpetas de triadas\n",
    "            baseline_files = []\n",
    "            experimental_files = []\n",
    "\n",
    "            for triad_code in triad_codes.values():\n",
    "                # Buscar en subcarpetas basadas en triad_codes\n",
    "                baseline_files.extend(glob.glob(os.path.join(baseline_dir, triad_code, 'sum_absolute_helicity_*mednegra.txt')))\n",
    "                experimental_files.extend(glob.glob(os.path.join(exp_dir, triad_code, 'sum_absolute_helicity_*med*.txt')))\n",
    "\n",
    "            if lab == \"Lab_Betta\":\n",
    "                combinations1 = generate_combinations(baseline_files, experimental_files)\n",
    "                combinations1 = list(set(combinations1))\n",
    "            else:\n",
    "                combinations2 = generate_combinations(baseline_files, experimental_files)\n",
    "                combinations2 = list(set(combinations2))\n",
    "\n",
    "    for base_file1_betta, base_file2_betta, experimental_file_betta in combinations1:\n",
    "        for base_file1_gamma, base_file2_gamma, experimental_file_gamma in combinations2:\n",
    "            number1_betta = extract_number(base_file1_betta)\n",
    "            number2_betta = extract_number(base_file2_betta)\n",
    "            number_exp_betta = extract_number(experimental_file_betta)\n",
    "            number1_gamma = extract_number(base_file1_gamma)\n",
    "            number2_gamma = extract_number(base_file2_gamma)\n",
    "            number_exp_gamma = extract_number(experimental_file_gamma)\n",
    "            triada1_betta = extract_triada(base_file1_betta)\n",
    "            triada2_betta = extract_triada(base_file2_betta)\n",
    "            triada_exp_betta = extract_triada(experimental_file_betta)\n",
    "            triada1_gamma = extract_triada(base_file1_gamma)\n",
    "            triada2_gamma = extract_triada(base_file1_gamma)\n",
    "            triada_exp_gamma = extract_triada(experimental_file_gamma)\n",
    "            \n",
    "            if (number1_betta == number1_gamma and number2_betta == number2_gamma and number_exp_betta == number_exp_gamma and \n",
    "                triada1_betta == triada2_betta == triada_exp_betta and \n",
    "                triada1_gamma == triada2_gamma == triada_exp_gamma and \n",
    "                triada1_betta == triada1_gamma and \n",
    "                triada2_betta == triada2_gamma and \n",
    "                triada_exp_betta == triada_exp_gamma):\n",
    "                plot_comparison(base_file1_betta, base_file2_betta, experimental_file_betta,\n",
    "                            base_file1_gamma, base_file2_gamma, experimental_file_gamma,\n",
    "                            output_directory, shift, date_str)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5 \n",
    "$$\n",
    "\\Huge \\text{First Integer Enstrophy Betta vs Gamma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitiendo cálculo para Lab_Betta V ya que el directorio no existe.\n",
      "Omitiendo cálculo para Lab_Gamma V ya que el directorio no existe.\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLP_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\RTB_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLP_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLP_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRP_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLP_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLT_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\RTB_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLT_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\LTB_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\LTB_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLT_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRB_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\LTB_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRP_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLB_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\RTB_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRP_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRT_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRT_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLB_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLB_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRB_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRT_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\LTB_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRB_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRB_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLT_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRB_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRB_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRT_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRT_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLT_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLT_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRP_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRB_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLB_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\RTB_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLB_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLT_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLB_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRT_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FLB_velocity\\Sum_Enstrophy_Comparison_03_04_03_03_04_03.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\FRB_velocity\\Sum_Enstrophy_Comparison_01_02_01_01_02_01.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLT_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PLB_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRT_velocity\\Sum_Enstrophy_Comparison_04_05_04_04_05_04.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Graphics\\Sum_Enstrophy_Comp\\PRT_velocity\\Sum_Enstrophy_Comparison_02_03_02_02_03_02.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# Diccionario de triadas y códigos\n",
    "triad_codes = {\n",
    "    (0, 2, 4): \"FRT\",  \n",
    "    (1, 3, 5): \"PLB\",  \n",
    "    (0, 3, 4): \"FLT\",  \n",
    "    (1, 2, 5): \"PRB\",  \n",
    "    (0, 2, 5): \"FRB\",  \n",
    "    (1, 3, 4): \"PLT\",  \n",
    "    (0, 3, 5): \"FLB\",  \n",
    "    (1, 2, 4): \"PRT\",  \n",
    "    (2, 4, 5): \"RTB\",  \n",
    "    (0, 1, 3): \"FLP\",  \n",
    "    (3, 4, 5): \"LTB\",  \n",
    "    (0, 1, 2): \"FRP\"\n",
    "}\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'velocity_(\\d+)med', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def read_data(filepath):\n",
    "    timestamps = []\n",
    "    values = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                timestamps.append(timestamp)\n",
    "                values.append(float(parts[1]))\n",
    "    return timestamps, np.array(values)\n",
    "\n",
    "def get_color(filename):\n",
    "    color_map = {\n",
    "        'medroja.txt': 'red',\n",
    "        'medmorada.txt': 'purple',\n",
    "        'medazul.txt': 'blue',\n",
    "        'medverde.txt': 'green',\n",
    "        'medamarilla.txt': 'yellow',\n",
    "        'mednaranja.txt': 'orange'\n",
    "    }\n",
    "    for suffix, color in color_map.items():\n",
    "        if suffix in filename:\n",
    "            return color\n",
    "    return 'gray'  # Default color if no match found\n",
    "\n",
    "def plot_comparison(base_file1_betta, base_file2_betta, experimental_file_betta,\n",
    "                    base_file1_gamma, base_file2_gamma, experimental_file_gamma,\n",
    "                    output_dir, shift, date_str):\n",
    "    # Leer los datos de Lab_Betta\n",
    "    timestamps_base1_betta, base_values1_betta = read_data(base_file1_betta)\n",
    "    timestamps_base2_betta, base_values2_betta = read_data(base_file2_betta)\n",
    "    timestamps_experimental_betta, experimental_values_betta = read_data(experimental_file_betta)\n",
    "\n",
    "    # Leer los datos de Lab_Gamma\n",
    "    timestamps_base1_gamma, base_values1_gamma = read_data(base_file1_gamma)\n",
    "    timestamps_base2_gamma, base_values2_gamma = read_data(base_file2_gamma)\n",
    "    timestamps_experimental_gamma, experimental_values_gamma = read_data(experimental_file_gamma)\n",
    "\n",
    "    # Reiniciar todas las estampas de tiempo para Lab_Betta\n",
    "    start_time_base1_betta = timestamps_base1_betta[0]\n",
    "    start_time_base2_betta = timestamps_base2_betta[0]\n",
    "    start_time_experimental_betta = timestamps_experimental_betta[0]\n",
    "    timestamps_base1_betta = [(ts - start_time_base1_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_base1_betta]\n",
    "    timestamps_base2_betta = [(ts - start_time_base2_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_base2_betta]\n",
    "    timestamps_experimental_betta = [(ts - start_time_experimental_betta + datetime.datetime(1900, 1, 1)) for ts in timestamps_experimental_betta]\n",
    "\n",
    "    # Reiniciar todas las estampas de tiempo para Lab_Gamma\n",
    "    start_time_base1_gamma = timestamps_base1_gamma[0]\n",
    "    start_time_base2_gamma = timestamps_base2_gamma[0]\n",
    "    start_time_experimental_gamma = timestamps_experimental_gamma[0]\n",
    "    timestamps_base1_gamma = [(ts - start_time_base1_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_base1_gamma]\n",
    "    timestamps_base2_gamma = [(ts - start_time_base2_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_base2_gamma]\n",
    "    timestamps_experimental_gamma = [(ts - start_time_experimental_gamma + datetime.datetime(1900, 1, 1)) for ts in timestamps_experimental_gamma]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "    base_times1_betta = mdates.date2num(timestamps_base1_betta)\n",
    "    base_times2_betta = mdates.date2num(timestamps_base2_betta)\n",
    "    experimental_times_betta = mdates.date2num(timestamps_experimental_betta)\n",
    "\n",
    "    base_times1_gamma = mdates.date2num(timestamps_base1_gamma)\n",
    "    base_times2_gamma = mdates.date2num(timestamps_base2_gamma)\n",
    "    experimental_times_gamma = mdates.date2num(timestamps_experimental_gamma)\n",
    "    \n",
    "    # Obtener las triadas para los títulos\n",
    "    triada_betta = extract_triada(experimental_file_betta)\n",
    "    triada_gamma = extract_triada(experimental_file_gamma)\n",
    "\n",
    "    # Usar los nombres descriptivos de las triadas en los títulos\n",
    "    triad_name_betta = triad_names.get(triada_betta, triada_betta)\n",
    "    triad_name_gamma = triad_names.get(triada_gamma, triada_gamma)\n",
    "\n",
    "    # Lab_Betta gráfico\n",
    "    ax1.plot(base_times1_betta, base_values1_betta, c='black', label=os.path.basename(base_file1_betta))\n",
    "    ax1.plot(base_times2_betta, base_values2_betta, c='gray', label=os.path.basename(base_file2_betta))\n",
    "    ax1.plot(experimental_times_betta, experimental_values_betta, c=get_color(experimental_file_betta), label=os.path.basename(experimental_file_betta))\n",
    "    ax1.set_title(f'Lab_Betta - {shift} - Date: {date_str} - {triad_name_betta}', fontsize=14)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Value')\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Lab_Gamma gráfico\n",
    "    ax2.plot(base_times1_gamma, base_values1_gamma, c='black', label=os.path.basename(base_file1_gamma))\n",
    "    ax2.plot(base_times2_gamma, base_values2_gamma, c='gray', label=os.path.basename(base_file2_gamma))\n",
    "    ax2.plot(experimental_times_gamma, experimental_values_gamma, c=get_color(experimental_file_gamma), label=os.path.basename(experimental_file_gamma))\n",
    "    ax2.set_title(f'Lab_Gamma - {shift} - Date: {date_str} - {triad_name_gamma}', fontsize=14)\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Value')\n",
    "    ax2.legend()\n",
    "    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Generar un nombre más corto para cada gráfico\n",
    "    number1_betta = extract_number(base_file1_betta)\n",
    "    number2_betta = extract_number(base_file2_betta)\n",
    "    number_exp_betta = extract_number(experimental_file_betta)\n",
    "    number1_gamma = extract_number(base_file1_gamma)\n",
    "    number2_gamma = extract_number(base_file2_gamma)\n",
    "    number_exp_gamma = extract_number(experimental_file_gamma)\n",
    "\n",
    "    output_filename = (f\"Sum_Enstrophy_Comparison_{number1_betta}_{number2_betta}_{number_exp_betta}_\"\n",
    "                   f\"{number1_gamma}_{number2_gamma}_{number_exp_gamma}.png\")\n",
    "\n",
    "    # Determinar la carpeta de salida en función del código de triada del archivo experimental de Lab_Betta\n",
    "    triad_code_betta = re.search(r'vorticity_(\\w+)_', experimental_file_betta)\n",
    "    if triad_code_betta:\n",
    "        triad_code_betta = triad_code_betta.group(1)\n",
    "        specific_output_dir = os.path.join(output_dir, triad_code_betta)\n",
    "    else:\n",
    "        specific_output_dir = output_dir\n",
    "\n",
    "    if not os.path.exists(specific_output_dir):\n",
    "        os.makedirs(specific_output_dir)\n",
    "\n",
    "    output_filepath = os.path.join(specific_output_dir, output_filename)\n",
    "    plt.savefig(output_filepath)\n",
    "    print(f\"Saved plot as {output_filepath}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def generate_combinations(baseline_files, experimental_files):\n",
    "    combinations = []\n",
    "    # Extraer triadas de los nombres de los archivos\n",
    "    baseline_triads = set()\n",
    "    experimental_triads = set()\n",
    "\n",
    "    for f in baseline_files:\n",
    "        match = re.search(r'vorticity_(\\w+)_', f)\n",
    "        if match:\n",
    "            baseline_triads.add(match.group(1))\n",
    "\n",
    "    for f in experimental_files:\n",
    "        match = re.search(r'vorticity_(\\w+)_', f)\n",
    "        if match:\n",
    "            experimental_triads.add(match.group(1))\n",
    "\n",
    "    # Generar combinaciones solo para triadas comunes\n",
    "    common_triads = baseline_triads.intersection(experimental_triads)\n",
    "    for triad in common_triads:\n",
    "        baseline_files_for_triad = [f for f in baseline_files if f\"vorticity_{triad}_\" in f]\n",
    "        experimental_files_for_triad = [f for f in experimental_files if f\"vorticity_{triad}_\" in f]\n",
    "        \n",
    "        # Asegurarse de que hay al menos dos archivos base para cada triada\n",
    "        if len(baseline_files_for_triad) >= 2:\n",
    "            for i, base_file1 in enumerate(baseline_files_for_triad):\n",
    "                for base_file2 in baseline_files_for_triad[i+1:]:\n",
    "                    for exp_file in experimental_files_for_triad:\n",
    "                        number1 = int(extract_number(base_file1))\n",
    "                        number2 = int(extract_number(base_file2))\n",
    "                        number_exp = int(extract_number(exp_file))\n",
    "                        if number1 == number_exp == ((number2)-1):\n",
    "                            combinations.append((base_file1, base_file2, exp_file))\n",
    "    return combinations\n",
    "\n",
    "def extract_triada(ruta):\n",
    "    # Extrae el nombre del archivo de la ruta\n",
    "    nombre_archivo = os.path.basename(ruta)\n",
    "    \n",
    "    # Busca y extrae la triada\n",
    "    match_triada = re.search(r'(FLB|FRP|PLB|PRB|FRT|PRT|FLT|PLT|RTB|LTB|FRB|FLP)', nombre_archivo)\n",
    "    triada = match_triada.group(1) if match_triada else None\n",
    "    \n",
    "    return triada\n",
    "\n",
    "def main():\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    combinations1 = []  # Definir una lista para combinaciones de Lab_Betta\n",
    "    combinations2 = []  # Definir una lista para combinaciones de Lab_Gamma\n",
    "\n",
    "    for lab in labs:\n",
    "        for shift in shifts:\n",
    "            lab_dirs = glob.glob(os.path.join(root_folder, f\"*{lab}\"))\n",
    "            if not lab_dirs:\n",
    "                print(f\"No se encontró ningún directorio para {lab}.\")\n",
    "                continue\n",
    "            lab_dir = lab_dirs[0]\n",
    "            date_str = os.path.basename(lab_dir).split(' ')[0]\n",
    "\n",
    "            baseline_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Sum_Enstrophy_Baseline\")\n",
    "            exp_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Sum_Enstrophy_Experimental_Color\")\n",
    "            output_directory = os.path.join(root_folder, \"Data Analysis\", \"Graphics\", \"Sum_Enstrophy_Comp\")\n",
    "\n",
    "            if not os.path.exists(baseline_dir) or not os.path.exists(exp_dir):\n",
    "                print(f\"Omitiendo cálculo para {lab} {shift} ya que el directorio no existe.\")\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(output_directory):\n",
    "                os.makedirs(output_directory)\n",
    "\n",
    "            # Buscar en subcarpetas de triadas\n",
    "            baseline_files = []\n",
    "            experimental_files = []\n",
    "\n",
    "            for triad_code in triad_codes.values():\n",
    "                # Buscar en subcarpetas basadas en triad_codes\n",
    "                baseline_files.extend(glob.glob(os.path.join(baseline_dir, triad_code, 'sum_enstrophy_vorticity_*mednegra.txt')))\n",
    "                experimental_files.extend(glob.glob(os.path.join(exp_dir, triad_code, 'sum_enstrophy_vorticity_*med*.txt')))\n",
    "\n",
    "            if lab == \"Lab_Betta\":\n",
    "                combinations1 = generate_combinations(baseline_files, experimental_files)\n",
    "                combinations1 = list(set(combinations1))\n",
    "            else:\n",
    "                combinations2 = generate_combinations(baseline_files, experimental_files)\n",
    "                combinations2 = list(set(combinations2))\n",
    "\n",
    "    for base_file1_betta, base_file2_betta, experimental_file_betta in combinations1:\n",
    "        for base_file1_gamma, base_file2_gamma, experimental_file_gamma in combinations2:\n",
    "            number1_betta = extract_number(base_file1_betta)\n",
    "            number2_betta = extract_number(base_file2_betta)\n",
    "            number_exp_betta = extract_number(experimental_file_betta)\n",
    "            number1_gamma = extract_number(base_file1_gamma)\n",
    "            number2_gamma = extract_number(base_file2_gamma)\n",
    "            number_exp_gamma = extract_number(experimental_file_gamma)\n",
    "            triada1_betta = extract_triada(base_file1_betta)\n",
    "            triada2_betta = extract_triada(base_file2_betta)\n",
    "            triada_exp_betta = extract_triada(experimental_file_betta)\n",
    "            triada1_gamma = extract_triada(base_file1_gamma)\n",
    "            triada2_gamma = extract_triada(base_file1_gamma)\n",
    "            triada_exp_gamma = extract_triada(experimental_file_gamma)\n",
    "            \n",
    "            if (number1_betta == number1_gamma and number2_betta == number2_gamma and number_exp_betta == number_exp_gamma and triada1_betta == triada2_betta == triada_exp_betta and \n",
    "                triada1_gamma == triada2_gamma == triada_exp_gamma and \n",
    "                triada1_betta == triada1_gamma and \n",
    "                triada2_betta == triada2_gamma and \n",
    "                triada_exp_betta == triada_exp_gamma):\n",
    "                plot_comparison(base_file1_betta, base_file2_betta, experimental_file_betta,\n",
    "                            base_file1_gamma, base_file2_gamma, experimental_file_gamma,\n",
    "                            output_directory, shift, date_str)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\n",
    "\n",
    "\n",
    "$$\n",
    "    \\Huge \\text{3D Curl Comparisons }\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitiendo cálculo para el turno V ya que uno o más directorios no existen.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Función para leer datos del sensor\n",
    "def read_data(filepath):\n",
    "    timestamps = []\n",
    "    values = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                try:\n",
    "                    timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                    timestamps.append(timestamp)\n",
    "                    values.append([float(num) for num in parts[1].strip('()').split(',')])\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing line in file {filepath}: {line}\\n{e}\")\n",
    "    return timestamps, np.array(values)\n",
    "\n",
    "# Función para comparar y graficar los laboratorios\n",
    "def plot_comparison_labs(baseline_file_betta, exp_file_betta, color_betta, baseline_file_gamma, exp_file_gamma, color_gamma, output_directory, shift, date_str):\n",
    "    try:\n",
    "        _, baseline_values_betta = read_data(baseline_file_betta)\n",
    "        _, exp_values_betta = read_data(exp_file_betta)\n",
    "        _, baseline_values_gamma = read_data(baseline_file_gamma)\n",
    "        _, exp_values_gamma = read_data(exp_file_gamma)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data files:\\n{e}\")\n",
    "        return\n",
    "\n",
    "    shift_label = \"Vespertino\" if shift == \"V\" else \"Matutino\"\n",
    "\n",
    "    fig = plt.figure(figsize=(24, 10))\n",
    "\n",
    "    # Subgráfica para el laboratorio Betta\n",
    "    ax_betta = fig.add_subplot(121, projection='3d')\n",
    "    ax_betta.scatter(baseline_values_betta[:, 0], baseline_values_betta[:, 1], baseline_values_betta[:, 2], c='black', label=os.path.basename(baseline_file_betta), s=50, alpha=0.6)\n",
    "    ax_betta.scatter(exp_values_betta[:, 0], exp_values_betta[:, 1], exp_values_betta[:, 2], c=color_betta, label=os.path.basename(exp_file_betta), s=50, alpha=0.6)\n",
    "    ax_betta.set_title(f'Lab Betta - {shift_label} Shift - Date: {date_str}', fontsize=20)\n",
    "    ax_betta.set_xlabel('X', fontsize=15)\n",
    "    ax_betta.set_ylabel('Y', fontsize=15)\n",
    "    ax_betta.set_zlabel('Z', fontsize=15)\n",
    "    legend_betta = ax_betta.legend(fontsize=14, loc='upper left', frameon=True, framealpha=0.9)\n",
    "    for handle in legend_betta.legend_handles:\n",
    "        handle.set_sizes([300])\n",
    "\n",
    "    # Subgráfica para el laboratorio Gamma\n",
    "    ax_gamma = fig.add_subplot(122, projection='3d')\n",
    "    ax_gamma.scatter(baseline_values_gamma[:, 0], baseline_values_gamma[:, 1], baseline_values_gamma[:, 2], c='black', label=os.path.basename(baseline_file_gamma), s=50, alpha=0.6)\n",
    "    ax_gamma.scatter(exp_values_gamma[:, 0], exp_values_gamma[:, 1], exp_values_gamma[:, 2], c=color_gamma, label=os.path.basename(exp_file_gamma), s=50, alpha=0.6)\n",
    "    ax_gamma.set_title(f'Lab Gamma - {shift_label} Shift - Date: {date_str}', fontsize=20)\n",
    "    ax_gamma.set_xlabel('X', fontsize=15)\n",
    "    ax_gamma.set_ylabel('Y', fontsize=15)\n",
    "    ax_gamma.set_zlabel('Z', fontsize=15)\n",
    "    legend_gamma = ax_gamma.legend(fontsize=14, loc='upper left', frameon=True, framealpha=0.9)\n",
    "    for handle in legend_gamma.legend_handles:\n",
    "        handle.set_sizes([300])\n",
    "\n",
    "    def update(frame):\n",
    "        ax_betta.view_init(elev=10, azim=frame)\n",
    "        ax_gamma.view_init(elev=10, azim=frame)\n",
    "        return fig,\n",
    "\n",
    "    output_filename = f\"{os.path.basename(baseline_file_betta).replace('mednegra', 'comparison_betta_vs_gamma')}_{os.path.basename(exp_file_betta)}\"\n",
    "    output_filepath = os.path.join(output_directory, output_filename)\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=100, blit=False)\n",
    "    ani.save(f'{output_filepath}.gif', writer='pillow', fps=10)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Función principal para procesar los archivos de ambos laboratorios\n",
    "def main(root_folder):\n",
    "    date_str = os.path.basename(root_folder)\n",
    "    date_str = date_str.replace(\"-2\", \"\").strip()\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    color_map = {\n",
    "        \"medroja.txt\": \"red\",\n",
    "        \"medmorada.txt\": \"purple\",\n",
    "        \"medazul.txt\": \"blue\",\n",
    "        \"medverde.txt\": \"green\",\n",
    "        \"medamarilla.txt\": \"yellow\"\n",
    "    }\n",
    "\n",
    "    for shift in shifts:\n",
    "        lab_betta_dirs = glob.glob(os.path.join(root_folder, f\"*Lab_Betta\"))\n",
    "        lab_gamma_dirs = glob.glob(os.path.join(root_folder, f\"*Lab_Gamma\"))\n",
    "\n",
    "        if not lab_betta_dirs:\n",
    "            print(\"No se encontró el directorio para Lab Betta.\")\n",
    "            continue\n",
    "        if not lab_gamma_dirs:\n",
    "            print(\"No se encontró el directorio para Lab Gamma.\")\n",
    "            continue\n",
    "\n",
    "        lab_betta_dir = lab_betta_dirs[0]\n",
    "        lab_gamma_dir = lab_gamma_dirs[0]\n",
    "\n",
    "        betta_baseline_dir = os.path.join(lab_betta_dir, f\"{date_str}.{shift} - Lab_Betta\", \"Data Analysis\", \"Processing Data\", \"Curl_Baseline\")\n",
    "        betta_exp_dir = os.path.join(lab_betta_dir, f\"{date_str}.{shift} - Lab_Betta\", \"Data Analysis\", \"Processing Data\", \"Curl_Experimental_Color\")\n",
    "\n",
    "        gamma_baseline_dir = os.path.join(lab_gamma_dir, f\"{date_str}.{shift} - Lab_Gamma\", \"Data Analysis\", \"Processing Data\", \"Curl_Baseline\")\n",
    "        gamma_exp_dir = os.path.join(lab_gamma_dir, f\"{date_str}.{shift} - Lab_Gamma\", \"Data Analysis\", \"Processing Data\", \"Curl_Experimental_Color\")\n",
    "\n",
    "        output_directory = os.path.join(root_folder, \"Data Analysis\", \"3D Curl Comparissons\")\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "\n",
    "        # Omitir si alguna de las carpetas requeridas no existe\n",
    "        if not os.path.exists(betta_baseline_dir) or not os.path.exists(betta_exp_dir) or not os.path.exists(gamma_baseline_dir) or not os.path.exists(gamma_exp_dir):\n",
    "            print(f\"Omitiendo cálculo para el turno {shift} ya que uno o más directorios no existen.\")\n",
    "            continue\n",
    "\n",
    "        betta_baseline_files = [f for f in os.listdir(betta_baseline_dir) if f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "        gamma_baseline_files = [f for f in os.listdir(gamma_baseline_dir) if f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "\n",
    "        betta_exp_files = [f for f in os.listdir(betta_exp_dir) if any(f.endswith(suffix) for suffix in color_map.keys()) and \"00\" not in f]\n",
    "        gamma_exp_files = [f for f in os.listdir(gamma_exp_dir) if any(f.endswith(suffix) for suffix in color_map.keys()) and \"00\" not in f]\n",
    "\n",
    "        # Verificar que hay archivos para procesar\n",
    "        if not betta_baseline_files or not gamma_baseline_files or not betta_exp_files or not gamma_exp_files:\n",
    "            print(f\"Omitiendo cálculo para el turno {shift} ya que no se encontraron archivos de base o experimentales en uno de los laboratorios.\")\n",
    "            continue\n",
    "\n",
    "        combinations_betta = generate_combinations(betta_baseline_files, betta_exp_files)\n",
    "        combinations_gamma = generate_combinations(gamma_baseline_files, gamma_exp_files)\n",
    "\n",
    "        # Asumiendo que las combinaciones tienen el mismo número de pares para Betta y Gamma\n",
    "        for (base_betta, exp_betta), (base_gamma, exp_gamma) in zip(combinations_betta, combinations_gamma):\n",
    "            baseline_file_betta = os.path.join(betta_baseline_dir, base_betta)\n",
    "            experimental_file_betta = os.path.join(betta_exp_dir, exp_betta)\n",
    "            baseline_file_gamma = os.path.join(gamma_baseline_dir, base_gamma)\n",
    "            experimental_file_gamma = os.path.join(gamma_exp_dir, exp_gamma)\n",
    "\n",
    "            if os.path.exists(baseline_file_betta) and os.path.exists(experimental_file_betta) and os.path.exists(baseline_file_gamma) and os.path.exists(experimental_file_gamma):\n",
    "                exp_suffix_betta = ''.join([i for i in os.path.basename(experimental_file_betta).split('curl_')[-1] if not i.isdigit()])\n",
    "                exp_suffix_gamma = ''.join([i for i in os.path.basename(experimental_file_gamma).split('curl_')[-1] if not i.isdigit()])\n",
    "                color_betta = color_map.get(exp_suffix_betta, 'black')\n",
    "                color_gamma = color_map.get(exp_suffix_gamma, 'black')\n",
    "                plot_comparison_labs(baseline_file_betta, experimental_file_betta, color_betta, baseline_file_gamma, experimental_file_gamma, color_gamma, output_directory, shift, date_str)\n",
    "\n",
    "# Generar combinaciones de archivos de línea base y experimentales\n",
    "def generate_combinations(baseline_files, exp_files):\n",
    "    # Mantener la misma lógica que genera combinaciones relevantes como en el código original\n",
    "    combinations = []\n",
    "    for base_file in baseline_files:\n",
    "        base_num = int(base_file.split('med')[0][-2:])\n",
    "        for exp_file in exp_files:\n",
    "            exp_num = int(exp_file.split('med')[0][-2:])\n",
    "            if exp_num == base_num or exp_num == base_num - 1:\n",
    "                combinations.append((base_file, exp_file))\n",
    "    return combinations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(root_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\n",
    "\n",
    "$$\n",
    " \\Huge \\text{Individual 3D Curl Baseline vs Experimental Color}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Diccionario con los nombres de las triadas\n",
    "triad_names = {\n",
    "    \"FRT\": \"Frontal-Derecho-Superior\",\n",
    "    \"PLB\": \"Trasero-Izquierdo-Inferior\",\n",
    "    \"FLT\": \"Frontal-Izquierdo-Superior\",\n",
    "    \"PRB\": \"Trasero-Derecho-Inferior\",\n",
    "    \"FRB\": \"Frontal-Derecho-Inferior\",\n",
    "    \"PLT\": \"Trasero-Izquierdo-Superior\",\n",
    "    \"FLB\": \"Frontal-Izquierdo-Inferior\",\n",
    "    \"PRT\": \"Trasero-Derecho-Superior\",\n",
    "    \"RTB\": \"Derecho-Superior-Inferior\",\n",
    "    \"FLP\": \"Frontal-Izquierdo-Trasero\",\n",
    "    \"LTB\": \"Izquierdo-Superior-Inferior\",\n",
    "    \"FRP\": \"Frontal-Derecho-Trasero\"\n",
    "}\n",
    "\n",
    "# Función para leer datos del sensor\n",
    "def read_data(filepath):\n",
    "    timestamps = []\n",
    "    values = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                try:\n",
    "                    timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                    timestamps.append(timestamp)\n",
    "                    values.append([float(num) for num in parts[1].strip('()').split(',')])\n",
    "                except ValueError as e:\n",
    "                    print(f\"Error processing line in file {filepath}: {line}\\n{e}\")\n",
    "    return timestamps, np.array(values)\n",
    "\n",
    "# Función para extraer el código de triada desde el nombre del archivo\n",
    "def extract_triad_code(filename):\n",
    "    # Asumimos que el código de la triada está en el nombre del archivo\n",
    "    for code in triad_names:\n",
    "        if code in filename:\n",
    "            return code\n",
    "    return \"Desconocido\"\n",
    "\n",
    "# Función para comparar y graficar los laboratorios\n",
    "def plot_comparison_labs(baseline_file_betta, exp_file_betta, color_betta, baseline_file_gamma, exp_file_gamma, color_gamma, output_directory, shift, date_str):\n",
    "    try:\n",
    "        _, baseline_values_betta = read_data(baseline_file_betta)\n",
    "        _, exp_values_betta = read_data(exp_file_betta)\n",
    "        _, baseline_values_gamma = read_data(baseline_file_gamma)\n",
    "        _, exp_values_gamma = read_data(exp_file_gamma)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data files:\\n{e}\")\n",
    "        return\n",
    "\n",
    "    shift_label = \"Vespertino\" if shift == \"V\" else \"Matutino\"\n",
    "\n",
    "    # Extraer los códigos de las triadas desde los nombres de los archivos\n",
    "    triad_code_betta = extract_triad_code(baseline_file_betta)\n",
    "    triad_code_gamma = extract_triad_code(baseline_file_gamma)\n",
    "\n",
    "    triad_name_betta = triad_names.get(triad_code_betta, \"Desconocido\")\n",
    "    triad_name_gamma = triad_names.get(triad_code_gamma, \"Desconocido\")\n",
    "\n",
    "    fig = plt.figure(figsize=(24, 10))\n",
    "\n",
    "    # Subgráfica para el laboratorio Betta\n",
    "    ax_betta = fig.add_subplot(121, projection='3d')\n",
    "    ax_betta.scatter(baseline_values_betta[:, 0], baseline_values_betta[:, 1], baseline_values_betta[:, 2], c='black', label=os.path.basename(baseline_file_betta), s=50, alpha=0.6)\n",
    "    ax_betta.scatter(exp_values_betta[:, 0], exp_values_betta[:, 1], exp_values_betta[:, 2], c=color_betta, label=os.path.basename(exp_file_betta), s=50, alpha=0.6)\n",
    "    ax_betta.set_title(f'Lab Betta - {shift_label} Shift - {triad_name_betta} - Date: {date_str}', fontsize=20)\n",
    "    ax_betta.set_xlabel('X', fontsize=15)\n",
    "    ax_betta.set_ylabel('Y', fontsize=15)\n",
    "    ax_betta.set_zlabel('Z', fontsize=15)\n",
    "    legend_betta = ax_betta.legend(fontsize=14, loc='upper left', frameon=True, framealpha=0.9)\n",
    "    for handle in legend_betta.legend_handles:\n",
    "        handle.set_sizes([300])\n",
    "\n",
    "    # Subgráfica para el laboratorio Gamma\n",
    "    ax_gamma = fig.add_subplot(122, projection='3d')\n",
    "    ax_gamma.scatter(baseline_values_gamma[:, 0], baseline_values_gamma[:, 1], baseline_values_gamma[:, 2], c='black', label=os.path.basename(baseline_file_gamma), s=50, alpha=0.6)\n",
    "    ax_gamma.scatter(exp_values_gamma[:, 0], exp_values_gamma[:, 1], exp_values_gamma[:, 2], c=color_gamma, label=os.path.basename(exp_file_gamma), s=50, alpha=0.6)\n",
    "    ax_gamma.set_title(f'Lab Gamma - {shift_label} Shift - {triad_name_gamma} - Date: {date_str}', fontsize=20)\n",
    "    ax_gamma.set_xlabel('X', fontsize=15)\n",
    "    ax_gamma.set_ylabel('Y', fontsize=15)\n",
    "    ax_gamma.set_zlabel('Z', fontsize=15)\n",
    "    legend_gamma = ax_gamma.legend(fontsize=14, loc='upper left', frameon=True, framealpha=0.9)\n",
    "    for handle in legend_gamma.legend_handles:\n",
    "        handle.set_sizes([300])\n",
    "\n",
    "    def update(frame):\n",
    "        ax_betta.view_init(elev=10, azim=frame)\n",
    "        ax_gamma.view_init(elev=10, azim=frame)\n",
    "        return fig,\n",
    "\n",
    "    output_filename = f\"{os.path.basename(baseline_file_betta).replace('mednegra', 'comparison_betta_vs_gamma')}_{os.path.basename(exp_file_betta)}\"\n",
    "    output_filepath = os.path.join(output_directory, output_filename)\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=np.arange(0, 360, 2), interval=100, blit=False)\n",
    "    ani.save(f'{output_filepath}.gif', writer='pillow', fps=10)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Función principal para procesar los archivos de ambos laboratorios\n",
    "def main(root_folder):\n",
    "    date_str = os.path.basename(root_folder)\n",
    "    date_str = date_str.replace(\"-2\", \"\").strip()\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    color_map = {\n",
    "        \"medroja.txt\": \"red\",\n",
    "        \"medmorada.txt\": \"purple\",\n",
    "        \"medazul.txt\": \"blue\",\n",
    "        \"medverde.txt\": \"green\",\n",
    "        \"medamarilla.txt\": \"yellow\"\n",
    "    }\n",
    "\n",
    "    for shift in shifts:\n",
    "        lab_betta_dirs = glob.glob(os.path.join(root_folder, f\"*Lab_Betta\"))\n",
    "        lab_gamma_dirs = glob.glob(os.path.join(root_folder, f\"*Lab_Gamma\"))\n",
    "\n",
    "        if not lab_betta_dirs:\n",
    "            print(\"No se encontró el directorio para Lab Betta.\")\n",
    "            continue\n",
    "        if not lab_gamma_dirs:\n",
    "            print(\"No se encontró el directorio para Lab Gamma.\")\n",
    "            continue\n",
    "\n",
    "        lab_betta_dir = lab_betta_dirs[0]\n",
    "        lab_gamma_dir = lab_gamma_dirs[0]\n",
    "\n",
    "        betta_baseline_dir = os.path.join(lab_betta_dir, f\"{date_str}.{shift} - Lab_Betta\", \"Data Analysis\", \"Processing Data\", \"Curl_Baseline\")\n",
    "        betta_exp_dir = os.path.join(lab_betta_dir, f\"{date_str}.{shift} - Lab_Betta\", \"Data Analysis\", \"Processing Data\", \"Curl_Experimental_Color\")\n",
    "\n",
    "        gamma_baseline_dir = os.path.join(lab_gamma_dir, f\"{date_str}.{shift} - Lab_Gamma\", \"Data Analysis\", \"Processing Data\", \"Curl_Baseline\")\n",
    "        gamma_exp_dir = os.path.join(lab_gamma_dir, f\"{date_str}.{shift} - Lab_Gamma\", \"Data Analysis\", \"Processing Data\", \"Curl_Experimental_Color\")\n",
    "\n",
    "        output_directory = os.path.join(root_folder, \"Data Analysis\", \"3D Curl Comparissons\")\n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "\n",
    "        # Omitir si alguna de las carpetas requeridas no existe\n",
    "        if not os.path.exists(betta_baseline_dir) or not os.path.exists(betta_exp_dir) or not os.path.exists(gamma_baseline_dir) or not os.path.exists(gamma_exp_dir):\n",
    "            print(f\"Omitiendo cálculo para el turno {shift} ya que uno o más directorios no existen.\")\n",
    "            continue\n",
    "\n",
    "        betta_baseline_files = [f for f in os.listdir(betta_baseline_dir) if f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "        gamma_baseline_files = [f for f in os.listdir(gamma_baseline_dir) if f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "\n",
    "        betta_exp_files = [f for f in os.listdir(betta_exp_dir) if f.endswith('.txt') and not f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "        gamma_exp_files = [f for f in os.listdir(gamma_exp_dir) if f.endswith('.txt') and not f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "\n",
    "        # Procesar cada archivo correspondiente\n",
    "        for betta_baseline_file in betta_baseline_files:\n",
    "            for exp_file_betta in betta_exp_files:\n",
    "                for gamma_baseline_file in gamma_baseline_files:\n",
    "                    for exp_file_gamma in gamma_exp_files:\n",
    "                        betta_baseline_path = os.path.join(betta_baseline_dir, betta_baseline_file)\n",
    "                        exp_file_betta_path = os.path.join(betta_exp_dir, exp_file_betta)\n",
    "                        gamma_baseline_path = os.path.join(gamma_baseline_dir, gamma_baseline_file)\n",
    "                        exp_file_gamma_path = os.path.join(gamma_exp_dir, exp_file_gamma)\n",
    "\n",
    "                        betta_color = color_map.get(exp_file_betta, \"blue\")\n",
    "                        gamma_color = color_map.get(exp_file_gamma, \"blue\")\n",
    "\n",
    "                        plot_comparison_labs(betta_baseline_path, exp_file_betta_path, betta_color, gamma_baseline_path, exp_file_gamma_path, gamma_color, output_directory, shift, date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\n",
    "\n",
    "$$\n",
    "  \\Huge \\text{Velocity Field  Baseline  Nivel}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitiendo cálculo para Lab_Betta V ya que el directorio no existe.\n",
      "Omitiendo cálculo para Lab_Gamma V ya que el directorio no existe.\n"
     ]
    }
   ],
   "source": [
    "#Curvas de Nivel Experimentals\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# Diccionario de triadas y códigos\n",
    "triad_codes = {\n",
    "    (0, 2, 4): \"FRT\",  \n",
    "    (1, 3, 5): \"PLB\",  \n",
    "    (0, 3, 4): \"FLT\",  \n",
    "    (1, 2, 5): \"PRB\",  \n",
    "    (0, 2, 5): \"FRB\",  \n",
    "    (1, 3, 4): \"PLT\",  \n",
    "    (0, 3, 5): \"FLB\",  \n",
    "    (1, 2, 4): \"PRT\",  \n",
    "    (2, 4, 5): \"RTB\",  \n",
    "    (0, 1, 3): \"FLP\",  \n",
    "    (3, 4, 5): \"LTB\",  \n",
    "    (0, 1, 2): \"FRP\"\n",
    "}\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'velocity_(\\d+)med', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def read_data(filepath):\n",
    "    \"\"\"\n",
    "    Extrae datos del archivo y los devuelve como arrays de x, y, z.\n",
    "    \"\"\"\n",
    "    timestamps = []\n",
    "    values_x = []\n",
    "    values_y = []\n",
    "    values_z = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                # Parsear el timestamp\n",
    "                timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                timestamps.append(timestamp)\n",
    "\n",
    "                # Remover paréntesis antes de convertir a float\n",
    "                coords_str = parts[1].strip().replace('(', '').replace(')', '')\n",
    "                coords = list(map(float, coords_str.split(',')))  # Convertir a float\n",
    "                values_x.append(coords[0])\n",
    "                values_y.append(coords[1])\n",
    "                values_z.append(coords[2])\n",
    "    \n",
    "    return np.array(values_x), np.array(values_y), np.array(values_z)\n",
    "\n",
    "def plot_contour(x, y, z, output_file):\n",
    "    \"\"\"\n",
    "    Genera y guarda la gráfica de curvas de nivel.\n",
    "    \"\"\"\n",
    "    # Crear una malla de puntos (grid) para la interpolación\n",
    "    grid_x, grid_y = np.mgrid[min(x):max(x):100j, min(y):max(y):100j]\n",
    "\n",
    "    # Interpolación de los valores de z en la malla\n",
    "    grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "    # Crear la gráfica de curvas de nivel\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    contour = plt.contourf(grid_x, grid_y, grid_z, cmap='viridis')\n",
    "    plt.colorbar(contour)\n",
    "    plt.title('Curvas de Nivel')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    # Guardar la gráfica\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "def process_files(file_list, output_dir):\n",
    "    \"\"\"\n",
    "    Procesa una lista de archivos, genera y guarda gráficos de curvas de nivel para cada uno.\n",
    "    \"\"\"\n",
    "    for file_path in file_list:\n",
    "        x, y, z = read_data(file_path)\n",
    "        triada = next((code for code, value in triad_codes.items() if value in os.path.basename(file_path)), None)\n",
    "        if not triada:\n",
    "            continue\n",
    "\n",
    "        triada_code = triad_codes.get(triada)\n",
    "        output_dir_triade = os.path.join(output_dir, triada_code)\n",
    "\n",
    "        if not os.path.exists(output_dir_triade):\n",
    "            os.makedirs(output_dir_triade)\n",
    "\n",
    "        file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_file = os.path.join(output_dir_triade, f\"{file_name}_contour.png\")\n",
    "        plot_contour(x, y, z, output_file)\n",
    "\n",
    "def main():\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    for shift in shifts:\n",
    "        lab_dirs = [glob.glob(os.path.join(root_folder, f\"*{lab}\")) for lab in labs]\n",
    "\n",
    "        if len(lab_dirs[0]) == 0 or len(lab_dirs[1]) == 0:\n",
    "            print(\"No se encontraron directorios para uno o ambos laboratorios.\")\n",
    "            continue\n",
    "\n",
    "        lab_dirs = [lab_dirs[i][0] for i in range(len(labs))]\n",
    "\n",
    "        for lab_idx, lab in enumerate(labs):\n",
    "            lab_dir = lab_dirs[lab_idx]\n",
    "            date_str = os.path.basename(lab_dir).split(' ')[0]\n",
    "\n",
    "            baseline_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Velocity_Baseline\")\n",
    "            \n",
    "            output_directory_baseline = os.path.join(root_folder, \"Data Analysis\", \"Graphics\", \"Velocity_Baseline_Nivel\", lab)\n",
    "\n",
    "            if not os.path.exists(baseline_dir):\n",
    "                print(f\"Omitiendo cálculo para {lab} {shift} ya que el directorio no existe.\")\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(output_directory_baseline):\n",
    "                os.makedirs(output_directory_baseline)\n",
    "\n",
    "            # Buscar archivos en directorios de triadas\n",
    "            baseline_files = []\n",
    "\n",
    "            for triad_code in triad_codes.values():\n",
    "                baseline_files.extend(glob.glob(os.path.join(baseline_dir, triad_code, 'velocity_*med*.txt')))\n",
    "\n",
    "            # Procesar archivos de línea base\n",
    "            process_files(baseline_files, output_directory_baseline)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\n",
    "\n",
    "$$\n",
    "  \\Huge \\text{Velocity Field  MEI  Nivel}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitiendo cálculo para Lab_Betta V ya que el directorio no existe.\n",
      "Omitiendo cálculo para Lab_Gamma V ya que el directorio no existe.\n"
     ]
    }
   ],
   "source": [
    "#Curvas de Nivel Baselines\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "# Diccionario de triadas y códigos\n",
    "triad_codes = {\n",
    "    (0, 2, 4): \"FRT\",  \n",
    "    (1, 3, 5): \"PLB\",  \n",
    "    (0, 3, 4): \"FLT\",  \n",
    "    (1, 2, 5): \"PRB\",  \n",
    "    (0, 2, 5): \"FRB\",  \n",
    "    (1, 3, 4): \"PLT\",  \n",
    "    (0, 3, 5): \"FLB\",  \n",
    "    (1, 2, 4): \"PRT\",  \n",
    "    (2, 4, 5): \"RTB\",  \n",
    "    (0, 1, 3): \"FLP\",  \n",
    "    (3, 4, 5): \"LTB\",  \n",
    "    (0, 1, 2): \"FRP\"\n",
    "}\n",
    "\n",
    "def extract_number(filename):\n",
    "    match = re.search(r'velocity_(\\d+)med', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def read_data(filepath):\n",
    "    \"\"\"\n",
    "    Extrae datos del archivo y los devuelve como arrays de x, y, z.\n",
    "    \"\"\"\n",
    "    timestamps = []\n",
    "    values_x = []\n",
    "    values_y = []\n",
    "    values_z = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                # Parsear el timestamp\n",
    "                timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                timestamps.append(timestamp)\n",
    "\n",
    "                # Remover paréntesis antes de convertir a float\n",
    "                coords_str = parts[1].strip().replace('(', '').replace(')', '')\n",
    "                coords = list(map(float, coords_str.split(',')))  # Convertir a float\n",
    "                values_x.append(coords[0])\n",
    "                values_y.append(coords[1])\n",
    "                values_z.append(coords[2])\n",
    "    \n",
    "    return np.array(values_x), np.array(values_y), np.array(values_z)\n",
    "\n",
    "def plot_contour(x, y, z, output_file):\n",
    "    \"\"\"\n",
    "    Genera y guarda la gráfica de curvas de nivel.\n",
    "    \"\"\"\n",
    "    # Crear una malla de puntos (grid) para la interpolación\n",
    "    grid_x, grid_y = np.mgrid[min(x):max(x):100j, min(y):max(y):100j]\n",
    "\n",
    "    # Interpolación de los valores de z en la malla\n",
    "    grid_z = griddata((x, y), z, (grid_x, grid_y), method='cubic')\n",
    "\n",
    "    # Crear la gráfica de curvas de nivel\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    contour = plt.contourf(grid_x, grid_y, grid_z, cmap='viridis')\n",
    "    plt.colorbar(contour)\n",
    "    plt.title('Curvas de Nivel')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    \n",
    "    # Guardar la gráfica\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "def process_files(file_list, output_dir):\n",
    "    \"\"\"\n",
    "    Procesa una lista de archivos, genera y guarda gráficos de curvas de nivel para cada uno.\n",
    "    \"\"\"\n",
    "    for file_path in file_list:\n",
    "        x, y, z = read_data(file_path)\n",
    "        triada = next((code for code, value in triad_codes.items() if value in os.path.basename(file_path)), None)\n",
    "        if not triada:\n",
    "            continue\n",
    "\n",
    "        triada_code = triad_codes.get(triada)\n",
    "        output_dir_triade = os.path.join(output_dir, triada_code)\n",
    "\n",
    "        if not os.path.exists(output_dir_triade):\n",
    "            os.makedirs(output_dir_triade)\n",
    "\n",
    "        file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        output_file = os.path.join(output_dir_triade, f\"{file_name}_contour.png\")\n",
    "        plot_contour(x, y, z, output_file)\n",
    "\n",
    "def main():\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    for shift in shifts:\n",
    "        lab_dirs = [glob.glob(os.path.join(root_folder, f\"*{lab}\")) for lab in labs]\n",
    "\n",
    "        if len(lab_dirs[0]) == 0 or len(lab_dirs[1]) == 0:\n",
    "            print(\"No se encontraron directorios para uno o ambos laboratorios.\")\n",
    "            continue\n",
    "\n",
    "        lab_dirs = [lab_dirs[i][0] for i in range(len(labs))]\n",
    "\n",
    "        for lab_idx, lab in enumerate(labs):\n",
    "            lab_dir = lab_dirs[lab_idx]\n",
    "            date_str = os.path.basename(lab_dir).split(' ')[0]\n",
    "\n",
    "            exp_dir = os.path.join(lab_dir, f\"{date_str}.{shift} - {lab}\", \"Data Analysis\", \"Processing Data\", \"Velocity_Experimental_Color\")\n",
    "            \n",
    "            output_directory_experimental = os.path.join(root_folder, \"Data Analysis\", \"Graphics\", \"Velocity_Experimental_Nivel\", lab)\n",
    "\n",
    "            if not os.path.exists(exp_dir):\n",
    "                print(f\"Omitiendo cálculo para {lab} {shift} ya que el directorio no existe.\")\n",
    "                continue\n",
    "\n",
    "            if not os.path.exists(output_directory_experimental):\n",
    "                os.makedirs(output_directory_experimental)\n",
    "\n",
    "            # Buscar archivos en directorios de triadas\n",
    "            experimental_files = []\n",
    "\n",
    "            for triad_code in triad_codes.values():\n",
    "                experimental_files.extend(glob.glob(os.path.join(exp_dir, triad_code, 'velocity_*med*.txt')))\n",
    "\n",
    "            # Procesar archivos experimentales\n",
    "            process_files(experimental_files, output_directory_experimental)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10\n",
    "\n",
    "$$\n",
    "\\Huge \\text{Comparison Moduli before and after for MEI}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omitiendo cálculo para el turno V: directorio basal o experimental no existe para uno de los laboratorios.\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Moduli Comparisons\\Comparison_Triad_Betta_vs_Gamma_magnitude_02mednegra_VS_magnitude_02mednegra.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Moduli Comparisons\\Comparison_Triad_Betta_vs_Gamma_magnitude_03mednegra_VS_magnitude_03mednegra.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Moduli Comparisons\\Comparison_Triad_Betta_vs_Gamma_magnitude_04mednegra_VS_magnitude_04mednegra.png\n",
      "Saved plot as E:\\Pruebas\\14Sep24\\Data Analysis\\Moduli Comparisons\\Comparison_Triad_Betta_vs_Gamma_magnitude_05mednegra_VS_magnitude_05mednegra.png\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------COMPARACIÓN MODULO LAB_BETTA VS MODULO LAB_GAMMA----------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def read_data(filepath):\n",
    "    timestamps = []\n",
    "    values = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split(' -> ')\n",
    "            if len(parts) > 1:\n",
    "                timestamp = datetime.datetime.strptime(parts[0], \"%H:%M:%S.%f\")\n",
    "                timestamps.append(timestamp)\n",
    "                values.append(float(parts[1]))\n",
    "    return timestamps, np.array(values)\n",
    "\n",
    "def get_color(filename):\n",
    "    color_map = {\n",
    "        'mednegra.txt': 'black',\n",
    "        'medroja.txt': 'red',\n",
    "        'medmorada.txt': 'purple',\n",
    "        'medazul.txt': 'blue',\n",
    "        'medverde.txt': 'green',\n",
    "        'medamarilla.txt': 'yellow'\n",
    "    }\n",
    "    for suffix, color in color_map.items():\n",
    "        if suffix in filename:\n",
    "            return color\n",
    "    return 'gray'  # Default color if no match found\n",
    "\n",
    "def plot_triad_comparison(betta_baseline_file, betta_experimental_file, betta_baseline_file2,\n",
    "                          gamma_baseline_file, gamma_experimental_file, gamma_baseline_file2,\n",
    "                          output_dir, shift, date_str):\n",
    "    # Leer datos de los archivos de ambos laboratorios\n",
    "    timestamps_betta_baseline, betta_baseline_values = read_data(betta_baseline_file)\n",
    "    timestamps_betta_experimental, betta_experimental_values = read_data(betta_experimental_file)\n",
    "    timestamps_betta_baseline2, betta_baseline_values2 = read_data(betta_baseline_file2)\n",
    "    \n",
    "    timestamps_gamma_baseline, gamma_baseline_values = read_data(gamma_baseline_file)\n",
    "    timestamps_gamma_experimental, gamma_experimental_values = read_data(gamma_experimental_file)\n",
    "    timestamps_gamma_baseline2, gamma_baseline_values2 = read_data(gamma_baseline_file2)\n",
    "\n",
    "    # Reiniciar todas las estampas de tiempo\n",
    "    start_time_betta_baseline = timestamps_betta_baseline[0]\n",
    "    start_time_betta_experimental = timestamps_betta_experimental[0]\n",
    "    start_time_betta_baseline2 = timestamps_betta_baseline2[0]\n",
    "    \n",
    "    start_time_gamma_baseline = timestamps_gamma_baseline[0]\n",
    "    start_time_gamma_experimental = timestamps_gamma_experimental[0]\n",
    "    start_time_gamma_baseline2 = timestamps_gamma_baseline2[0]\n",
    "    \n",
    "    timestamps_betta_baseline = [(ts - start_time_betta_baseline + datetime.datetime(1900, 1, 1)) for ts in timestamps_betta_baseline]\n",
    "    timestamps_betta_experimental = [(ts - start_time_betta_experimental + datetime.datetime(1900, 1, 1)) for ts in timestamps_betta_experimental]\n",
    "    timestamps_betta_baseline2 = [(ts - start_time_betta_baseline2 + datetime.datetime(1900, 1, 1)) for ts in timestamps_betta_baseline2]\n",
    "\n",
    "    timestamps_gamma_baseline = [(ts - start_time_gamma_baseline + datetime.datetime(1900, 1, 1)) for ts in timestamps_gamma_baseline]\n",
    "    timestamps_gamma_experimental = [(ts - start_time_gamma_experimental + datetime.datetime(1900, 1, 1)) for ts in timestamps_gamma_experimental]\n",
    "    timestamps_gamma_baseline2 = [(ts - start_time_gamma_baseline2 + datetime.datetime(1900, 1, 1)) for ts in timestamps_gamma_baseline2]\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8))\n",
    "\n",
    "    # Graficar Lab Betta con tres series de tiempo\n",
    "    betta_baseline_times = mdates.date2num(timestamps_betta_baseline)\n",
    "    betta_experimental_times = mdates.date2num(timestamps_betta_experimental)\n",
    "    betta_baseline_times2 = mdates.date2num(timestamps_betta_baseline2)\n",
    "\n",
    "    ax1.plot(betta_baseline_times, betta_baseline_values, c='gray', label=os.path.basename(betta_baseline_file))\n",
    "    ax1.plot(betta_experimental_times, betta_experimental_values, c=get_color(betta_experimental_file), label=os.path.basename(betta_experimental_file))\n",
    "    ax1.plot(betta_baseline_times2, betta_baseline_values2, c='black', label=os.path.basename(betta_baseline_file2))\n",
    "    ax1.set_title(f'Lab Betta - Shift: {\"Vespertino\" if shift == \"V\" else \"Matutino\"} - Date: {date_str}', fontsize=14)\n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Magnitude')\n",
    "    ax1.legend()\n",
    "    ax1.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "\n",
    "    # Graficar Lab Gamma con tres series de tiempo\n",
    "    gamma_baseline_times = mdates.date2num(timestamps_gamma_baseline)\n",
    "    gamma_experimental_times = mdates.date2num(timestamps_gamma_experimental)\n",
    "    gamma_baseline_times2 = mdates.date2num(timestamps_gamma_baseline2)\n",
    "\n",
    "    ax2.plot(gamma_baseline_times, gamma_baseline_values, c='gray', label=os.path.basename(gamma_baseline_file))\n",
    "    ax2.plot(gamma_experimental_times, gamma_experimental_values, c=get_color(gamma_experimental_file), label=os.path.basename(gamma_experimental_file))\n",
    "    ax2.plot(gamma_baseline_times2, gamma_baseline_values2, c='black', label=os.path.basename(gamma_baseline_file2))\n",
    "    ax2.set_title(f'Lab Gamma - Shift: {\"Vespertino\" if shift == \"V\" else \"Matutino\"} - Date: {date_str}', fontsize=14)\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Magnitude')\n",
    "    ax2.legend()\n",
    "    ax2.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M:%S'))\n",
    "    \n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Generar un nombre único para cada gráfico\n",
    "    output_filename = f\"Comparison_Triad_Betta_vs_Gamma_{os.path.basename(betta_baseline_file).split('.')[0]}_VS_{os.path.basename(gamma_baseline_file).split('.')[0]}.png\"\n",
    "    output_filepath = os.path.join(output_dir, output_filename)\n",
    "    plt.savefig(output_filepath)\n",
    "    print(f\"Saved plot as {output_filepath}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def generate_combinations(baseline_files, experimental_files, baseline_files2):\n",
    "    combinations = []\n",
    "    for base_file in baseline_files:\n",
    "        base_num = int(base_file.split('med')[0][-2:])\n",
    "        for exp_file in experimental_files:\n",
    "            exp_num = int(exp_file.split('med')[0][-2:])\n",
    "            for base_file2 in baseline_files2:\n",
    "                base_num2 = int(base_file2.split('med')[0][-2:])\n",
    "                if exp_num == base_num - 1 and exp_num == base_num2:\n",
    "                    combinations.append((base_file, exp_file, base_file2))\n",
    "    return combinations\n",
    "\n",
    "def main():\n",
    "\n",
    "    labs = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    shifts = [\"V\", \"M\"]\n",
    "\n",
    "    color_map = {\n",
    "        \"mednegra.txt\": \"black\",\n",
    "        \"medroja.txt\": \"red\",\n",
    "        \"medmorada.txt\": \"purple\",\n",
    "        \"medazul.txt\": \"blue\",\n",
    "        \"medverde.txt\": \"green\",\n",
    "        \"medamarilla.txt\": \"yellow\"\n",
    "    }\n",
    "\n",
    "    for shift in shifts:\n",
    "        betta_dirs = glob.glob(os.path.join(root_folder, f\"*Lab_Betta\"))\n",
    "        gamma_dirs = glob.glob(os.path.join(root_folder, f\"*Lab_Gamma\"))\n",
    "        \n",
    "        if not betta_dirs or not gamma_dirs:\n",
    "            print(f\"No se encontró ningún directorio para {shift}.\")\n",
    "            continue\n",
    "\n",
    "        betta_dir = betta_dirs[0]\n",
    "        gamma_dir = gamma_dirs[0]\n",
    "\n",
    "        date_str = os.path.basename(betta_dir).split(' ')[0]\n",
    "\n",
    "        betta_baseline_dir = os.path.join(betta_dir, f\"{date_str}.{shift} - Lab_Betta\", \"Data Analysis\", \"Processing Data\", \"Moduli_Curl_Baseline\")\n",
    "        betta_exp_dir = os.path.join(betta_dir, f\"{date_str}.{shift} - Lab_Betta\", \"Data Analysis\", \"Processing Data\", \"Moduli_Curl_Experimental_Color\")\n",
    "\n",
    "        gamma_baseline_dir = os.path.join(gamma_dir, f\"{date_str}.{shift} - Lab_Gamma\", \"Data Analysis\", \"Processing Data\", \"Moduli_Curl_Baseline\")\n",
    "        gamma_exp_dir = os.path.join(gamma_dir, f\"{date_str}.{shift} - Lab_Gamma\", \"Data Analysis\", \"Processing Data\", \"Moduli_Curl_Experimental_Color\")\n",
    "\n",
    "        output_directory = os.path.join(root_folder, \"Data Analysis\", \"Moduli Comparisons\")\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "        if not os.path.exists(betta_baseline_dir) or not os.path.exists(betta_exp_dir) or not os.path.exists(gamma_baseline_dir) or not os.path.exists(gamma_exp_dir):\n",
    "            print(f\"Omitiendo cálculo para el turno {shift}: directorio basal o experimental no existe para uno de los laboratorios.\")\n",
    "            continue\n",
    "\n",
    "        betta_baseline_files = [f for f in os.listdir(betta_baseline_dir) if f.startswith('magnitude_') and f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "        betta_experimental_files = [f for f in os.listdir(betta_exp_dir) if f.startswith('magnitude_') and any(f.endswith(suffix) for suffix in color_map.keys()) and \"00\" not in f]\n",
    "        betta_baseline_files2 = [f for f in os.listdir(betta_baseline_dir) if f.startswith('magnitude_') and f.endswith('mednegra.txt') and \"00\" not in f and f != betta_baseline_files]\n",
    "\n",
    "        gamma_baseline_files = [f for f in os.listdir(gamma_baseline_dir) if f.startswith('magnitude_') and f.endswith('mednegra.txt') and \"00\" not in f]\n",
    "        gamma_experimental_files = [f for f in os.listdir(gamma_exp_dir) if f.startswith('magnitude_') and any(f.endswith(suffix) for suffix in color_map.keys()) and \"00\" not in f]\n",
    "        gamma_baseline_files2 = [f for f in os.listdir(gamma_baseline_dir) if f.startswith('magnitude_') and f.endswith('mednegra.txt') and \"00\" not in f and f != gamma_baseline_files]\n",
    "\n",
    "        betta_combinations = generate_combinations(betta_baseline_files, betta_experimental_files, betta_baseline_files2)\n",
    "        gamma_combinations = generate_combinations(gamma_baseline_files, gamma_experimental_files, gamma_baseline_files2)\n",
    "\n",
    "        for (betta_base_file, betta_exp_file, betta_base_file2), (gamma_base_file, gamma_exp_file, gamma_base_file2) in zip(betta_combinations, gamma_combinations):\n",
    "            betta_baseline_file = os.path.join(betta_baseline_dir, betta_base_file)\n",
    "            betta_experimental_file = os.path.join(betta_exp_dir, betta_exp_file)\n",
    "            betta_baseline_file2 = os.path.join(betta_baseline_dir, betta_base_file2)\n",
    "\n",
    "            gamma_baseline_file = os.path.join(gamma_baseline_dir, gamma_base_file)\n",
    "            gamma_experimental_file = os.path.join(gamma_exp_dir, gamma_exp_file)\n",
    "            gamma_baseline_file2 = os.path.join(gamma_baseline_dir, gamma_base_file2)\n",
    "\n",
    "            if all(os.path.exists(file) for file in [betta_baseline_file, betta_experimental_file, betta_baseline_file2, gamma_baseline_file, gamma_experimental_file, gamma_baseline_file2]):\n",
    "                plot_triad_comparison(betta_baseline_file, betta_experimental_file, betta_baseline_file2,\n",
    "                                      gamma_baseline_file, gamma_experimental_file, gamma_baseline_file2,\n",
    "                                      output_directory, shift, date_str)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11\n",
    "\n",
    "$$\n",
    "    \\Huge \\text{Comparison Derivatives Histograms}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando la carpeta raíz: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.M - Lab_Betta\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.M - Lab_Betta\n",
      "\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.M - Lab_Betta\\Negra\n",
      "   Archivo ignorado: 001mednegra.txt\n",
      "   Archivo ignorado: 002mednegra.txt\n",
      "   Encontrado y procesado: 01mednegra.txt\n",
      "   Encontrado y procesado: 02mednegra.txt\n",
      "   Encontrado y procesado: 03mednegra.txt\n",
      "   Encontrado y procesado: 04mednegra.txt\n",
      "   Encontrado y procesado: 05mednegra.txt\n",
      "\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.M - Lab_Betta\\Roja\n",
      "   Encontrado y procesado: 01medroja.txt\n",
      "   Encontrado y procesado: 02medroja.txt\n",
      "   Encontrado y procesado: 03medroja.txt\n",
      "   Encontrado y procesado: 04medroja.txt\n",
      "\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Betta\\14Sep24.M - Lab_Betta\\Roja\\Pesajes Roja\n",
      "   Archivo ignorado: 01medroja-pesajes.log\n",
      "   Archivo ignorado: 02medroja-pesajes.log\n",
      "   Archivo ignorado: 03medroja-pesajes.log\n",
      "   Archivo ignorado: 04medroja-pesajes.log\n",
      "\n",
      "\n",
      "No se encontró ningún directorio para Lab_Betta, V.\n",
      "Analizando la carpeta raíz: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.M - Lab_Gamma\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.M - Lab_Gamma\n",
      "\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.M - Lab_Gamma\\Graphics\n",
      "\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.M - Lab_Gamma\\Graphics\\Comparison\n",
      "   Archivo ignorado: comparacion_01_02_base_1_roja.pdf\n",
      "   Archivo ignorado: comparacion_02_03_base_2_roja.pdf\n",
      "   Archivo ignorado: comparacion_03_04_base_3_roja.pdf\n",
      "   Archivo ignorado: comparacion_04_05_base_4_roja.pdf\n",
      "\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.M - Lab_Gamma\\Negra\n",
      "   Archivo ignorado: 001mednegra.txt\n",
      "   Archivo ignorado: 002mednegra.txt\n",
      "   Encontrado y procesado: 01mednegra.txt\n",
      "   Encontrado y procesado: 02mednegra.txt\n",
      "   Encontrado y procesado: 03mednegra.txt\n",
      "   Encontrado y procesado: 04mednegra.txt\n",
      "   Encontrado y procesado: 05mednegra.txt\n",
      "\n",
      "\n",
      "Subdirectorio: E:\\Pruebas\\14Sep24\\14Sep24 - Lab_Gamma\\14Sep24.M - Lab_Gamma\\Roja\n",
      "   Encontrado y procesado: 01medroja.txt\n",
      "   Encontrado y procesado: 02medroja.txt\n",
      "   Encontrado y procesado: 03medroja.txt\n",
      "   Encontrado y procesado: 04medroja.txt\n",
      "\n",
      "\n",
      "No se encontró ningún directorio para Lab_Gamma, V.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "import re\n",
    "\n",
    "def read_sensor_data(filepath):\n",
    "    data = []\n",
    "    num_elements = None\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(' -> ')\n",
    "                if len(parts) > 1:\n",
    "                    numbers = parts[1].strip('()').split(',')\n",
    "                    try:\n",
    "                        number_list = [float(num.strip()) for num in numbers]\n",
    "                        if num_elements is None:\n",
    "                            num_elements = len(number_list)\n",
    "                        if len(number_list) == num_elements:\n",
    "                            data.append(number_list)\n",
    "                        else:\n",
    "                            print(f\"Inconsistent number of elements in file {filepath}, line: {line.strip()}\")\n",
    "                    except ValueError:\n",
    "                        print(f\"Value error in file {filepath}, line: {line.strip()}\")\n",
    "                        continue\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Unicode decode error in file {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filepath}: {e}\")\n",
    "    return np.array(data).T\n",
    "\n",
    "def analyze_folder(root_folder):\n",
    "    data_per_file = {}\n",
    "    print(f\"Analizando la carpeta raíz: {root_folder}\\n\")\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        dirs[:] = [d for d in dirs if d != \"Data Analysis\"]\n",
    "        print(f\"Subdirectorio: {root}\")\n",
    "        for filename in files:\n",
    "            if filename.endswith((\"negra.txt\", \"roja.txt\", \"morada.txt\", \"azul.txt\", \"verde.txt\", \"amarilla.txt\")) and not filename.startswith(\"00\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                data = read_sensor_data(file_path)\n",
    "                if data.size > 0:\n",
    "                    data_per_file[filename] = data\n",
    "                    print(f\"   Encontrado y procesado: {filename}\")\n",
    "                else:\n",
    "                    print(f\"   Archivo vacío o no procesable: {filename}\")\n",
    "            else:\n",
    "                print(f\"   Archivo ignorado: {filename}\")\n",
    "        print(\"\\n\")\n",
    "    return data_per_file\n",
    "\n",
    "def smooth_data(data, window_length=10, polyorder=3):\n",
    "    if len(data) < window_length:\n",
    "        window_length = len(data) - (len(data) % 2 == 0)\n",
    "    return savgol_filter(data, window_length=window_length, polyorder=polyorder)\n",
    "\n",
    "def plot_comparison_grid(data_per_file, output_folder, title_info, lab):\n",
    "    suffix_to_color = {\n",
    "        \"negra.txt\": \"black\",\n",
    "        \"roja.txt\": \"red\",\n",
    "        \"morada.txt\": \"purple\",\n",
    "        \"azul.txt\": \"blue\",\n",
    "        \"verde.txt\": \"green\",\n",
    "        \"amarilla.txt\": \"yellow\"\n",
    "    }\n",
    "    component_names = [\"FRONTAL\", \"TRASERO\", \"IZQUIERDA\", \"DERECHA\", \"SUPERIOR\", \"INFERIOR\"]\n",
    "\n",
    "    min_length = min((len(data[0]) for data in data_per_file.values() if data.size > 0), default=None)\n",
    "    if min_length is None:\n",
    "        print(\"No se encontraron datos válidos para procesar.\")\n",
    "        return\n",
    "\n",
    "    for base_key in sorted(data_per_file.keys()):\n",
    "        if \"negra.txt\" in base_key:\n",
    "            n = int(base_key.split('med')[0])\n",
    "            base_data_before = data_per_file[base_key][:, :min_length]\n",
    "            for exp_suffix in [\"roja.txt\", \"morada.txt\", \"azul.txt\", \"verde.txt\", \"amarilla.txt\"]:\n",
    "                exp_key = f\"{n:02d}med{exp_suffix}\"\n",
    "                base_key_after = f\"{n+1:02d}mednegra.txt\"\n",
    "                \n",
    "                if exp_key in data_per_file and base_key_after in data_per_file:\n",
    "                    exp_data = data_per_file[exp_key][:, :min_length]\n",
    "                    base_data_after = data_per_file[base_key_after][:, :min_length]\n",
    "\n",
    "                    fig, axes = plt.subplots(6, 2, figsize=(40, 60), dpi=300)\n",
    "                    for i, component in enumerate(component_names):\n",
    "                        ax_left = axes[i, 0]\n",
    "                        ax_right = axes[i, 1]\n",
    "                        smoothed_base_before = smooth_data(base_data_before[i])\n",
    "                        smoothed_exp = smooth_data(exp_data[i])\n",
    "                        smoothed_base_after = smooth_data(base_data_after[i])\n",
    "                        derivative_base_before = np.gradient(smoothed_base_before)\n",
    "                        derivative_exp = np.gradient(smoothed_exp)\n",
    "                        derivative_base_after = np.gradient(smoothed_base_after)\n",
    "\n",
    "                        # Histograma ajustado a formato similar a Mathematica\n",
    "                        ax_left.hist(derivative_base_before, bins=25, color='black', alpha=0.5, label=f'Base Antes: {base_key}', edgecolor='black', density=True, log=True)\n",
    "                        ax_left.hist(derivative_exp, bins=25, color=suffix_to_color[exp_suffix], alpha=0.7, label=f'Experimental: {exp_key}', edgecolor='black', density=True, log=True)\n",
    "                        ax_left.set_title(f\"{component} - Antes vs Exp\", fontsize=30)\n",
    "                        ax_left.set_xlabel(\"Valor Derivado\", fontsize=25)\n",
    "                        ax_left.set_ylabel(\"Probabilidad\", fontsize=25)\n",
    "                        ax_left.legend(fontsize=25)\n",
    "                        ax_left.tick_params(axis='both', labelsize=35)\n",
    "\n",
    "                        ax_right.hist(derivative_base_after, bins=25, color='black', alpha=0.5, label=f'Base Después: {base_key_after}', edgecolor='black', density=True, log=True)\n",
    "                        ax_right.hist(derivative_exp, bins=25, color=suffix_to_color[exp_suffix], alpha=0.7, label=f'Experimental: {exp_key}', edgecolor='black', density=True, log=True)\n",
    "                        ax_right.set_title(f\"{component} - Después vs Exp\", fontsize=30)\n",
    "                        ax_right.set_xlabel(\"Valor Derivado\", fontsize=25)\n",
    "                        ax_right.set_ylabel(\"Probabilidad\", fontsize=25)\n",
    "                        ax_right.legend(fontsize=25)\n",
    "                        ax_right.tick_params(axis='both', labelsize=35)\n",
    "\n",
    "                    date, shift = title_info\n",
    "                    shift_full = \"MATUTINO\" if shift == \"M\" else \"VESPERTINO\"\n",
    "                    plt.suptitle(f\"Comparaciones de Derivadas - {date} - {shift_full} - {lab}\", fontsize=50)\n",
    "                    plt.tight_layout(pad=5.0)\n",
    "                    output_file = os.path.join(output_folder, f\"deriv_{n:02d}_{exp_suffix.split('.')[0]}.pdf\")\n",
    "                    plt.savefig(output_file, bbox_inches='tight', format='pdf')\n",
    "                    plt.close()\n",
    "\n",
    "def find_experiment_folder(root_folder, lab, shift):\n",
    "    date_regex = re.compile(r'\\d{2}[A-Za-z]{3}\\d{2}')\n",
    "    for folder in os.listdir(root_folder):\n",
    "        if date_regex.search(folder) and lab in folder:\n",
    "            for subfolder in os.listdir(os.path.join(root_folder, folder)):\n",
    "                if date_regex.search(subfolder) and shift in subfolder:\n",
    "                    return os.path.join(root_folder, folder, subfolder), date_regex.search(folder).group(0)\n",
    "    return None, None\n",
    "\n",
    "def main():\n",
    "    laboratorios = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    turnos = [\"M\", \"V\"]\n",
    "\n",
    "    for lab in laboratorios:\n",
    "        for turno in turnos:\n",
    "            experiment_folder, date_str = find_experiment_folder(root_folder, lab, turno)\n",
    "            if not experiment_folder:\n",
    "                print(f\"No se encontró ningún directorio para {lab}, {turno}.\")\n",
    "                continue\n",
    "\n",
    "            output_folder = os.path.join(experiment_folder, \"Data Analysis\", \"Graphics\", \"Comparison_D[R]\")\n",
    "            os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "            title_info = (date_str, turno)\n",
    "\n",
    "            data_per_file = analyze_folder(experiment_folder)\n",
    "            plot_comparison_grid(data_per_file, output_folder, title_info, lab)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 12\n",
    "\n",
    "$$\n",
    "    \\Huge \\text{Comparison Time Series Laser}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se encontró ningún directorio para Lab_Betta, V.\n",
      "No se encontró ningún directorio para Lab_Gamma, V.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "import re\n",
    "\n",
    "def read_sensor_data(filepath):\n",
    "    data = []\n",
    "    num_elements = None\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                parts = line.strip().split(' -> ')\n",
    "                if len(parts) > 1:\n",
    "                    numbers = parts[1].strip('()').split(',')\n",
    "                    try:\n",
    "                        number_list = [float(num.strip()) for num in numbers]\n",
    "                        if num_elements is None:\n",
    "                            num_elements = len(number_list)\n",
    "                        if len(number_list) == num_elements:\n",
    "                            data.append(number_list)\n",
    "                        else:\n",
    "                            print(f\"Inconsistent number of elements in file {filepath}, line: {line.strip()}\")\n",
    "                    except ValueError:\n",
    "                        print(f\"Value error in file {filepath}, line: {line.strip()}\")\n",
    "                        continue\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Unicode decode error in file {filepath}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {filepath}: {e}\")\n",
    "    return np.array(data).T\n",
    "\n",
    "def analyze_folder(root_folder):\n",
    "    data_per_file = {}\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        dirs[:] = [d for d in dirs if d != \"Data Analysis\"]\n",
    "        for filename in files:\n",
    "            if filename.endswith((\"negra.txt\", \"roja.txt\", \"morada.txt\", \"azul.txt\", \"verde.txt\", \"amarilla.txt\", \"naranja.txt\")) and not filename.startswith(\"00\"):\n",
    "                file_path = os.path.join(root, filename)\n",
    "                data = read_sensor_data(file_path)\n",
    "                if data.size > 0:\n",
    "                    data_per_file[filename] = data\n",
    "    return data_per_file\n",
    "\n",
    "def smooth_data(data, window_length=10, polyorder=3):\n",
    "    if len(data) < window_length:\n",
    "        window_length = len(data) - (len(data) % 2 == 0)\n",
    "    return savgol_filter(data, window_length=window_length, polyorder=polyorder)\n",
    "\n",
    "def plot_comparison_grid(data_per_file, output_folder, title_info, lab):\n",
    "    suffix_to_color = {\n",
    "        \"negra.txt\": \"black\",\n",
    "        \"roja.txt\": \"red\",\n",
    "        \"morada.txt\": \"purple\",\n",
    "        \"azul.txt\": \"blue\",\n",
    "        \"verde.txt\": \"green\",\n",
    "        \"amarilla.txt\": \"yellow\",\n",
    "        \"naranja.txt\": \"orange\"\n",
    "    }\n",
    "    component_names = [\"FRONTAL\", \"TRASERO\", \"IZQUIERDA\", \"DERECHA\", \"SUPERIOR\", \"INFERIOR\"]\n",
    "\n",
    "    for base_key in sorted(data_per_file.keys()):\n",
    "        if \"negra.txt\" in base_key:\n",
    "            try:\n",
    "                n = int(re.search(r'\\d+', base_key.split('med')[0]).group())\n",
    "            except (ValueError, AttributeError):\n",
    "                print(f\"El archivo {base_key} no contiene un número válido para conversión.\")\n",
    "                continue\n",
    "\n",
    "            base_data_before = data_per_file[base_key]\n",
    "            for exp_suffix in [\"roja.txt\", \"morada.txt\", \"azul.txt\", \"verde.txt\", \"amarilla.txt\", \"naranja.txt\"]:\n",
    "                exp_key = f\"{n:02d}med{exp_suffix}\"\n",
    "                base_key_after = f\"{n+1:02d}mednegra.txt\"\n",
    "                if exp_key in data_per_file and base_key_after in data_per_file:\n",
    "                    exp_data = data_per_file[exp_key]\n",
    "                    base_data_after = data_per_file[base_key_after]\n",
    "                    fig, axes = plt.subplots(6, 2, figsize=(40, 60), dpi=300)\n",
    "                    axes = axes.reshape(-1, 2)\n",
    "                    for i, component in enumerate(component_names):\n",
    "                        ax_before = axes[i, 0]\n",
    "                        ax_after = axes[i, 1]\n",
    "                        smoothed_base_before = smooth_data(base_data_before[i])\n",
    "                        smoothed_exp = smooth_data(exp_data[i])\n",
    "                        smoothed_base_after = smooth_data(base_data_after[i])\n",
    "                        ax_before.plot(smoothed_base_before, label=f'Línea Base: {base_key}', color='black', linewidth=2)\n",
    "                        ax_before.plot(smoothed_exp, label=f'Experimental: {exp_key}', color=suffix_to_color[exp_suffix], linewidth=2)\n",
    "                        ax_before.set_title(f\"Componente {component} (Antes)\", fontsize=25)\n",
    "                        ax_before.set_xlabel(\"Registros\", fontsize=25)\n",
    "                        ax_before.set_ylabel(\"Volts\", fontsize=25)\n",
    "                        ax_before.tick_params(axis='both', which='major', labelsize=20)\n",
    "                        ax_before.legend(fontsize=30)\n",
    "                        ax_after.plot(smoothed_base_after, label=f'Línea Base: {base_key_after}', color='black', linewidth=2)\n",
    "                        ax_after.plot(smoothed_exp, label=f'Experimental: {exp_key}', color=suffix_to_color[exp_suffix], linewidth=2)\n",
    "                        ax_after.set_title(f\"Componente {component} (Después)\", fontsize=25)\n",
    "                        ax_after.set_xlabel(\"Registros\", fontsize=25)\n",
    "                        ax_after.set_ylabel(\"Volts\", fontsize=25)\n",
    "                        ax_after.tick_params(axis='both', which='major', labelsize=20)\n",
    "                        ax_after.legend(fontsize=30)\n",
    "                    date, shift = title_info\n",
    "                    shift_full = \"MATUTINO\" if shift == \"M\" else \"VESPERTINO\"\n",
    "                    color_name = exp_suffix.split('.')[0].upper()\n",
    "                    output_file = os.path.join(output_folder, f\"comparacion_{n:02d}_{n+1:02d}_base_{n}_{exp_suffix.split('.')[0]}.pdf\")\n",
    "                    plt.suptitle(f\"COMPARACIÓN BASE {n:02d} Y DESPUÉS {n+1:02d} DE INTERVENCIÓN - {date} - {shift_full} - INTERVENCIÓN: {color_name} - LABORATORIO: {lab}\", fontsize=35)\n",
    "                    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "                    plt.savefig(output_file, bbox_inches='tight', format='pdf')\n",
    "                    plt.close()\n",
    "\n",
    "def find_experiment_folder(root_folder, lab, turno):\n",
    "    date_regex = re.compile(r'\\d{2}[A-Za-z]{3}\\d{2}')\n",
    "    for folder in os.listdir(root_folder):\n",
    "        if date_regex.search(folder) and lab in folder:\n",
    "            for subfolder in os.listdir(os.path.join(root_folder, folder)):\n",
    "                if date_regex.search(subfolder) and turno in subfolder:\n",
    "                    return os.path.join(root_folder, folder, subfolder), date_regex.search(folder).group(0)\n",
    "    return None, None\n",
    "\n",
    "def main():\n",
    "    # Definir los laboratorios y turnos\n",
    "    laboratorios = [\"Lab_Betta\", \"Lab_Gamma\"]\n",
    "    turnos = [\"M\", \"V\"]\n",
    "\n",
    "\n",
    "    for lab in laboratorios:\n",
    "        for turno in turnos:\n",
    "            # Encontrar la carpeta del experimento correspondiente al laboratorio y turno\n",
    "            experiment_folder, date_str = find_experiment_folder(root_folder, lab, turno)\n",
    "            if not experiment_folder:\n",
    "                print(f\"No se encontró ningún directorio para {lab}, {turno}.\")\n",
    "                continue\n",
    "\n",
    "            # Acceder directamente a la carpeta del experimento para procesar datos sin entrar a \"Data Analysis\"\n",
    "            output_folder = os.path.join(experiment_folder,\"Data Analysis\", \"Graphics\", \"Comparison\")\n",
    "            os.makedirs(output_folder, exist_ok=True)  # Crear la carpeta de gráficos si no existe\n",
    "\n",
    "            title_info = (date_str, turno)\n",
    "\n",
    "            # Analizar los archivos en la carpeta del experimento directamente\n",
    "            data_per_file = analyze_folder(experiment_folder)\n",
    "            # Generar las gráficas y guardarlas en la carpeta de gráficos\n",
    "            plot_comparison_grid(data_per_file, output_folder, title_info, lab)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
